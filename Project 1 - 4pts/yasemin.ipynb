{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0921b3d3",
   "metadata": {},
   "source": [
    "# Text Mining: Project 1\n",
    "\n",
    "Group members:\n",
    "* Contadini Alice \n",
    "* Nguyen Thien \n",
    "* Uslu Yasemin \n",
    "\n",
    "Assigned character: Leonard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca021d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yasem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt') \n",
    "from nltk import pos_tag\n",
    "from nltk import FreqDist\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194ce4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54406"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dataset\n",
    "path = 'Scripts TBBT.csv'\n",
    "df = pd.read_csv(path, sep = \",\", skipinitialspace=True, engine=\"python\")\n",
    "len(df) # number of dialogues in complete dataset with all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d801140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>person_scene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td>Leonard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Excuse me?</td>\n",
       "      <td>Leonard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, ...</td>\n",
       "      <td>Leonard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Yes. Um, is this the High IQ sperm bank?</td>\n",
       "      <td>Leonard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Thank-you. We’ll be right back.</td>\n",
       "      <td>Leonard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            episode_name  \\\n",
       "2   Series 01 Episode 01 – Pilot Episode   \n",
       "4   Series 01 Episode 01 – Pilot Episode   \n",
       "6   Series 01 Episode 01 – Pilot Episode   \n",
       "8   Series 01 Episode 01 – Pilot Episode   \n",
       "12  Series 01 Episode 01 – Pilot Episode   \n",
       "\n",
       "                                             dialogue person_scene  \n",
       "2                          Agreed, what’s your point?      Leonard  \n",
       "4                                          Excuse me?      Leonard  \n",
       "6    One across is Aegean, eight down is Nabakov, ...      Leonard  \n",
       "8            Yes. Um, is this the High IQ sperm bank?      Leonard  \n",
       "12                    Thank-you. We’ll be right back.      Leonard  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter dataset (only Leonard)\n",
    "leonard_df = df[df['person_scene'] == 'Leonard'].copy()\n",
    "leonard_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059aa293",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "On average, how many sentences and words does your character have to speak per\n",
    "episode? Does this deviate across seasons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a586275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9638"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of dialogues of Leonard\n",
    "len(leonard_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32a3dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>person_scene</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Excuse me?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, ...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Yes. Um, is this the High IQ sperm bank?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Thank-you. We’ll be right back.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            episode_name  \\\n",
       "2   Series 01 Episode 01 – Pilot Episode   \n",
       "4   Series 01 Episode 01 – Pilot Episode   \n",
       "6   Series 01 Episode 01 – Pilot Episode   \n",
       "8   Series 01 Episode 01 – Pilot Episode   \n",
       "12  Series 01 Episode 01 – Pilot Episode   \n",
       "\n",
       "                                             dialogue person_scene  \\\n",
       "2                          Agreed, what’s your point?      Leonard   \n",
       "4                                          Excuse me?      Leonard   \n",
       "6    One across is Aegean, eight down is Nabakov, ...      Leonard   \n",
       "8            Yes. Um, is this the High IQ sperm bank?      Leonard   \n",
       "12                    Thank-you. We’ll be right back.      Leonard   \n",
       "\n",
       "    num_sentences  \n",
       "2               1  \n",
       "4               1  \n",
       "6               3  \n",
       "8               2  \n",
       "12              2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of sentences in each dialogue (row)\n",
    "leonard_df['num_sentences'] = leonard_df['dialogue'].apply(lambda x: len(sent_tokenize(str(x))))\n",
    "leonard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e57542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>person_scene</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>dialogue_no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Agreed  what s your point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Excuse me?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Excuse me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, ...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>3</td>\n",
       "      <td>One across is Aegean  eight down is Nabakov  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Yes. Um, is this the High IQ sperm bank?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes  Um  is this the High IQ sperm bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Thank-you. We’ll be right back.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Thank you  We ll be right back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>What, are you kidding? You’re a semi-pro.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>What  are you kidding  You re a semi pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Sheldon, this was your idea. A little extra m...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Sheldon  this was your idea  A little extra m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I’m sure she’ll still love him.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>I m sure she ll still love him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Well, what do you want to do?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Well  what do you want to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I don’t know, I’ve never reneged on a proffer...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>I don t know  I ve never reneged on a proffer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>See you.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>See you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>No.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Not really.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Not really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I don’t care. Two millimetres? That doesn’t se...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>3</td>\n",
       "      <td>I don t care  Two millimetres  That doesn t se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Is that why they sent you to boarding school?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Is that why they sent you to boarding school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>New neighbour?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>New neighbour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Significant improvement over the old neighbour.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Significant improvement over the old neighbour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>We don’t mean to interrupt, we live across th...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>We don t mean to interrupt  we live across th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Oh… uh… no… we don’t live together… um… we li...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh  uh  no  we don t live together  um  we li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Leonard, Sheldon.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard  Sheldon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi. Well, uh, oh, welcome to the building.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Hi  Well  uh  oh  welcome to the building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Oh, great.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh  great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Great. Well, bye.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Great  Well  bye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Bye.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Bye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Should we have invited her for lunch?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Should we have invited her for lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>We already watched the Season Two DVDs.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>We already watched the Season Two DVDs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I think we should be good neighbours, invite ...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>I think we should be good neighbours  invite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Well, then that was wrong of us. We need to w...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Well  then that was wrong of us  We need to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Yes, and you’ve never met one of them.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes  and you ve never met one of them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I’m going to invite her over. We’ll have a nic...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>I m going to invite her over  We ll have a nic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Well it’s not difficult, you just listen to w...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Well it s not difficult  you just listen to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi. Again.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Hi  Again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Anyway, um. We brought home Indian food. And,...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>5</td>\n",
       "      <td>Anyway  um  We brought home Indian food  And ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Uh, yes.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Uh  yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Great.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Okay, well, make yourself at home.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Okay  well  make yourself at home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>You’re very welcome.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>You re very welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I have a board. If you like boards, this is m...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>I have a board  If you like boards  this is m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>What?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>What</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>At least I didn’t have to invent twenty-six di...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>At least I didn t have to invent twenty six di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>In what universe?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>In what universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Here we go.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Here we go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Just sit somewhere else.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Just sit somewhere else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Sheldon, sit!</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheldon  sit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             episode_name  \\\n",
       "2    Series 01 Episode 01 – Pilot Episode   \n",
       "4    Series 01 Episode 01 – Pilot Episode   \n",
       "6    Series 01 Episode 01 – Pilot Episode   \n",
       "8    Series 01 Episode 01 – Pilot Episode   \n",
       "12   Series 01 Episode 01 – Pilot Episode   \n",
       "15   Series 01 Episode 01 – Pilot Episode   \n",
       "17   Series 01 Episode 01 – Pilot Episode   \n",
       "19   Series 01 Episode 01 – Pilot Episode   \n",
       "21   Series 01 Episode 01 – Pilot Episode   \n",
       "23   Series 01 Episode 01 – Pilot Episode   \n",
       "25   Series 01 Episode 01 – Pilot Episode   \n",
       "27   Series 01 Episode 01 – Pilot Episode   \n",
       "29   Series 01 Episode 01 – Pilot Episode   \n",
       "32   Series 01 Episode 01 – Pilot Episode   \n",
       "34   Series 01 Episode 01 – Pilot Episode   \n",
       "36   Series 01 Episode 01 – Pilot Episode   \n",
       "38   Series 01 Episode 01 – Pilot Episode   \n",
       "40   Series 01 Episode 01 – Pilot Episode   \n",
       "42   Series 01 Episode 01 – Pilot Episode   \n",
       "45   Series 01 Episode 01 – Pilot Episode   \n",
       "47   Series 01 Episode 01 – Pilot Episode   \n",
       "50   Series 01 Episode 01 – Pilot Episode   \n",
       "52   Series 01 Episode 01 – Pilot Episode   \n",
       "54   Series 01 Episode 01 – Pilot Episode   \n",
       "56   Series 01 Episode 01 – Pilot Episode   \n",
       "59   Series 01 Episode 01 – Pilot Episode   \n",
       "61   Series 01 Episode 01 – Pilot Episode   \n",
       "64   Series 01 Episode 01 – Pilot Episode   \n",
       "67   Series 01 Episode 01 – Pilot Episode   \n",
       "68   Series 01 Episode 01 – Pilot Episode   \n",
       "70   Series 01 Episode 01 – Pilot Episode   \n",
       "72   Series 01 Episode 01 – Pilot Episode   \n",
       "74   Series 01 Episode 01 – Pilot Episode   \n",
       "76   Series 01 Episode 01 – Pilot Episode   \n",
       "78   Series 01 Episode 01 – Pilot Episode   \n",
       "80   Series 01 Episode 01 – Pilot Episode   \n",
       "82   Series 01 Episode 01 – Pilot Episode   \n",
       "85   Series 01 Episode 01 – Pilot Episode   \n",
       "87   Series 01 Episode 01 – Pilot Episode   \n",
       "90   Series 01 Episode 01 – Pilot Episode   \n",
       "92   Series 01 Episode 01 – Pilot Episode   \n",
       "96   Series 01 Episode 01 – Pilot Episode   \n",
       "98   Series 01 Episode 01 – Pilot Episode   \n",
       "106  Series 01 Episode 01 – Pilot Episode   \n",
       "109  Series 01 Episode 01 – Pilot Episode   \n",
       "111  Series 01 Episode 01 – Pilot Episode   \n",
       "113  Series 01 Episode 01 – Pilot Episode   \n",
       "121  Series 01 Episode 01 – Pilot Episode   \n",
       "125  Series 01 Episode 01 – Pilot Episode   \n",
       "127  Series 01 Episode 01 – Pilot Episode   \n",
       "\n",
       "                                              dialogue person_scene  \\\n",
       "2                           Agreed, what’s your point?      Leonard   \n",
       "4                                           Excuse me?      Leonard   \n",
       "6     One across is Aegean, eight down is Nabakov, ...      Leonard   \n",
       "8             Yes. Um, is this the High IQ sperm bank?      Leonard   \n",
       "12                     Thank-you. We’ll be right back.      Leonard   \n",
       "15          What, are you kidding? You’re a semi-pro.       Leonard   \n",
       "17    Sheldon, this was your idea. A little extra m...      Leonard   \n",
       "19                     I’m sure she’ll still love him.      Leonard   \n",
       "21                       Well, what do you want to do?      Leonard   \n",
       "23                                               Okay.      Leonard   \n",
       "25    I don’t know, I’ve never reneged on a proffer...      Leonard   \n",
       "27                                               Okay.      Leonard   \n",
       "29                                            See you.      Leonard   \n",
       "32                                                 No.      Leonard   \n",
       "34                                         Not really.      Leonard   \n",
       "36   I don’t care. Two millimetres? That doesn’t se...      Leonard   \n",
       "38       Is that why they sent you to boarding school?      Leonard   \n",
       "40                                      New neighbour?      Leonard   \n",
       "42     Significant improvement over the old neighbour.      Leonard   \n",
       "45                                                 Hi.      Leonard   \n",
       "47                                                 Hi.      Leonard   \n",
       "50    We don’t mean to interrupt, we live across th...      Leonard   \n",
       "52    Oh… uh… no… we don’t live together… um… we li...      Leonard   \n",
       "54                                   Leonard, Sheldon.      Leonard   \n",
       "56                                                 Hi.      Leonard   \n",
       "59          Hi. Well, uh, oh, welcome to the building.      Leonard   \n",
       "61                                          Oh, great.      Leonard   \n",
       "64                                   Great. Well, bye.      Leonard   \n",
       "67                                               Bye.       Leonard   \n",
       "68               Should we have invited her for lunch?      Leonard   \n",
       "70             We already watched the Season Two DVDs.      Leonard   \n",
       "72    I think we should be good neighbours, invite ...      Leonard   \n",
       "74    Well, then that was wrong of us. We need to w...      Leonard   \n",
       "76              Yes, and you’ve never met one of them.      Leonard   \n",
       "78   I’m going to invite her over. We’ll have a nic...      Leonard   \n",
       "80    Well it’s not difficult, you just listen to w...      Leonard   \n",
       "82                                          Hi. Again.      Leonard   \n",
       "85                                                 Hi.      Leonard   \n",
       "87    Anyway, um. We brought home Indian food. And,...      Leonard   \n",
       "90                                            Uh, yes.      Leonard   \n",
       "92                                              Great.      Leonard   \n",
       "96                  Okay, well, make yourself at home.      Leonard   \n",
       "98                                You’re very welcome.      Leonard   \n",
       "106   I have a board. If you like boards, this is m...      Leonard   \n",
       "109                                              What?      Leonard   \n",
       "111  At least I didn’t have to invent twenty-six di...      Leonard   \n",
       "113                                  In what universe?      Leonard   \n",
       "121                                        Here we go.      Leonard   \n",
       "125                           Just sit somewhere else.      Leonard   \n",
       "127                                      Sheldon, sit!      Leonard   \n",
       "\n",
       "     num_sentences                                  dialogue_no_punct  \n",
       "2                1                         Agreed  what s your point   \n",
       "4                1                                         Excuse me   \n",
       "6                3   One across is Aegean  eight down is Nabakov  ...  \n",
       "8                2           Yes  Um  is this the High IQ sperm bank   \n",
       "12               2                    Thank you  We ll be right back   \n",
       "15               2         What  are you kidding  You re a semi pro    \n",
       "17               2   Sheldon  this was your idea  A little extra m...  \n",
       "19               1                    I m sure she ll still love him   \n",
       "21               1                      Well  what do you want to do   \n",
       "23               1                                              Okay   \n",
       "25               1   I don t know  I ve never reneged on a proffer...  \n",
       "27               1                                              Okay   \n",
       "29               1                                           See you   \n",
       "32               1                                                No   \n",
       "34               1                                        Not really   \n",
       "36               3  I don t care  Two millimetres  That doesn t se...  \n",
       "38               1      Is that why they sent you to boarding school   \n",
       "40               1                                     New neighbour   \n",
       "42               1    Significant improvement over the old neighbour   \n",
       "45               1                                                Hi   \n",
       "47               1                                                Hi   \n",
       "50               1   We don t mean to interrupt  we live across th...  \n",
       "52               1   Oh  uh  no  we don t live together  um  we li...  \n",
       "54               1                                  Leonard  Sheldon   \n",
       "56               1                                                Hi   \n",
       "59               2         Hi  Well  uh  oh  welcome to the building   \n",
       "61               1                                         Oh  great   \n",
       "64               2                                  Great  Well  bye   \n",
       "67               1                                              Bye    \n",
       "68               1              Should we have invited her for lunch   \n",
       "70               1            We already watched the Season Two DVDs   \n",
       "72               1   I think we should be good neighbours  invite ...  \n",
       "74               2   Well  then that was wrong of us  We need to w...  \n",
       "76               1             Yes  and you ve never met one of them   \n",
       "78               2  I m going to invite her over  We ll have a nic...  \n",
       "80               1   Well it s not difficult  you just listen to w...  \n",
       "82               2                                         Hi  Again   \n",
       "85               1                                                Hi   \n",
       "87               5   Anyway  um  We brought home Indian food  And ...  \n",
       "90               1                                           Uh  yes   \n",
       "92               1                                             Great   \n",
       "96               1                 Okay  well  make yourself at home   \n",
       "98               1                               You re very welcome   \n",
       "106              2   I have a board  If you like boards  this is m...  \n",
       "109              1                                              What   \n",
       "111              1  At least I didn t have to invent twenty six di...  \n",
       "113              1                                  In what universe   \n",
       "121              1                                        Here we go   \n",
       "125              1                           Just sit somewhere else   \n",
       "127              1                                      Sheldon  sit   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    punctuations = set('!“#$%&()*+,-.:;?@[]^‘’{|}~...')\n",
    "    \n",
    "    # Replace ellipsis with space\n",
    "    text = text.replace(\"\\u2026\", ' ')\n",
    "    \n",
    "    for char in punctuations:\n",
    "        text = text.replace(char, ' ')\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# Remove punctuation from dialogues\n",
    "leonard_df['dialogue_no_punct'] = leonard_df['dialogue'].apply(remove_punctuation) # New column with clean dialogues\n",
    "leonard_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48643cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>person_scene</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>dialogue_no_punct</th>\n",
       "      <th>dialogue_no_punct_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Agreed  what s your point</td>\n",
       "      <td>agreed  what s your point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Excuse me?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Excuse me</td>\n",
       "      <td>excuse me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, ...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>3</td>\n",
       "      <td>One across is Aegean  eight down is Nabakov  ...</td>\n",
       "      <td>one across is aegean  eight down is nabakov  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Yes. Um, is this the High IQ sperm bank?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes  Um  is this the High IQ sperm bank</td>\n",
       "      <td>yes  um  is this the high iq sperm bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Thank-you. We’ll be right back.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Thank you  We ll be right back</td>\n",
       "      <td>thank you  we ll be right back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            episode_name  \\\n",
       "2   Series 01 Episode 01 – Pilot Episode   \n",
       "4   Series 01 Episode 01 – Pilot Episode   \n",
       "6   Series 01 Episode 01 – Pilot Episode   \n",
       "8   Series 01 Episode 01 – Pilot Episode   \n",
       "12  Series 01 Episode 01 – Pilot Episode   \n",
       "\n",
       "                                             dialogue person_scene  \\\n",
       "2                          Agreed, what’s your point?      Leonard   \n",
       "4                                          Excuse me?      Leonard   \n",
       "6    One across is Aegean, eight down is Nabakov, ...      Leonard   \n",
       "8            Yes. Um, is this the High IQ sperm bank?      Leonard   \n",
       "12                    Thank-you. We’ll be right back.      Leonard   \n",
       "\n",
       "    num_sentences                                  dialogue_no_punct  \\\n",
       "2               1                         Agreed  what s your point    \n",
       "4               1                                         Excuse me    \n",
       "6               3   One across is Aegean  eight down is Nabakov  ...   \n",
       "8               2           Yes  Um  is this the High IQ sperm bank    \n",
       "12              2                    Thank you  We ll be right back    \n",
       "\n",
       "                              dialogue_no_punct_lower  \n",
       "2                          agreed  what s your point   \n",
       "4                                          excuse me   \n",
       "6    one across is aegean  eight down is nabakov  ...  \n",
       "8            yes  um  is this the high iq sperm bank   \n",
       "12                    thank you  we ll be right back   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leonard_df['dialogue_no_punct_lower'] = leonard_df['dialogue_no_punct'].apply(lambda x: x.lower())\n",
    "leonard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de552919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>person_scene</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>dialogue_no_punct</th>\n",
       "      <th>dialogue_no_punct_lower</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Agreed  what s your point</td>\n",
       "      <td>agreed  what s your point</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Excuse me?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Excuse me</td>\n",
       "      <td>excuse me</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, ...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>3</td>\n",
       "      <td>One across is Aegean  eight down is Nabakov  ...</td>\n",
       "      <td>one across is aegean  eight down is nabakov  ...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Yes. Um, is this the High IQ sperm bank?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes  Um  is this the High IQ sperm bank</td>\n",
       "      <td>yes  um  is this the high iq sperm bank</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Thank-you. We’ll be right back.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Thank you  We ll be right back</td>\n",
       "      <td>thank you  we ll be right back</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            episode_name  \\\n",
       "2   Series 01 Episode 01 – Pilot Episode   \n",
       "4   Series 01 Episode 01 – Pilot Episode   \n",
       "6   Series 01 Episode 01 – Pilot Episode   \n",
       "8   Series 01 Episode 01 – Pilot Episode   \n",
       "12  Series 01 Episode 01 – Pilot Episode   \n",
       "\n",
       "                                             dialogue person_scene  \\\n",
       "2                          Agreed, what’s your point?      Leonard   \n",
       "4                                          Excuse me?      Leonard   \n",
       "6    One across is Aegean, eight down is Nabakov, ...      Leonard   \n",
       "8            Yes. Um, is this the High IQ sperm bank?      Leonard   \n",
       "12                    Thank-you. We’ll be right back.      Leonard   \n",
       "\n",
       "    num_sentences                                  dialogue_no_punct  \\\n",
       "2               1                         Agreed  what s your point    \n",
       "4               1                                         Excuse me    \n",
       "6               3   One across is Aegean  eight down is Nabakov  ...   \n",
       "8               2           Yes  Um  is this the High IQ sperm bank    \n",
       "12              2                    Thank you  We ll be right back    \n",
       "\n",
       "                              dialogue_no_punct_lower  num_words  \n",
       "2                          agreed  what s your point           5  \n",
       "4                                          excuse me           2  \n",
       "6    one across is aegean  eight down is nabakov  ...         39  \n",
       "8            yes  um  is this the high iq sperm bank           9  \n",
       "12                    thank you  we ll be right back           7  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of words per dialogue (row)\n",
    "leonard_df['num_words'] = leonard_df['dialogue_no_punct'].apply(lambda x: len(word_tokenize(str(x)))) # word tokenization\n",
    "leonard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2fd92b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Series 01 Episode 02 – The Big Bran Hypothesis</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 03 – The Fuzzy Boots Corollary</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Series 01 Episode 04 – The Luminous Fish Effect</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 05 – The Hamburger Postulate</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Series 10 Episode 20 – The Recollection Dissip...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Series 10 Episode 21 – The Separation Agitation</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Series 10 Episode 22 – The Cognition Regeneration</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Series 10 Episode 23 – The Gyroscopic Collapse</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Series 10 Episode 24 – The Long Distance Disso...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          episode_name  num_sentences\n",
       "0                 Series 01 Episode 01 – Pilot Episode            164\n",
       "1       Series 01 Episode 02 – The Big Bran Hypothesis            116\n",
       "2     Series 01 Episode 03 – The Fuzzy Boots Corollary            156\n",
       "3      Series 01 Episode 04 – The Luminous Fish Effect             62\n",
       "4       Series 01 Episode 05 – The Hamburger Postulate             94\n",
       "..                                                 ...            ...\n",
       "226  Series 10 Episode 20 – The Recollection Dissip...             21\n",
       "227    Series 10 Episode 21 – The Separation Agitation             28\n",
       "228  Series 10 Episode 22 – The Cognition Regeneration             56\n",
       "229     Series 10 Episode 23 – The Gyroscopic Collapse             34\n",
       "230  Series 10 Episode 24 – The Long Distance Disso...             32\n",
       "\n",
       "[231 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentences per episode\n",
    "sentences_per_episode = leonard_df.groupby('episode_name')['num_sentences'].sum().reset_index()\n",
    "sentences_per_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a0c5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.926406926406926"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average sentences per episode \n",
    "avg_sentences_per_episode = sentences_per_episode['num_sentences'].mean()\n",
    "avg_sentences_per_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252e88a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Series 01 Episode 02 – The Big Bran Hypothesis</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 03 – The Fuzzy Boots Corollary</td>\n",
       "      <td>1399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Series 01 Episode 04 – The Luminous Fish Effect</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 05 – The Hamburger Postulate</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Series 10 Episode 20 – The Recollection Dissip...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Series 10 Episode 21 – The Separation Agitation</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Series 10 Episode 22 – The Cognition Regeneration</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Series 10 Episode 23 – The Gyroscopic Collapse</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Series 10 Episode 24 – The Long Distance Disso...</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          episode_name  num_words\n",
       "0                 Series 01 Episode 01 – Pilot Episode       1171\n",
       "1       Series 01 Episode 02 – The Big Bran Hypothesis        968\n",
       "2     Series 01 Episode 03 – The Fuzzy Boots Corollary       1399\n",
       "3      Series 01 Episode 04 – The Luminous Fish Effect        410\n",
       "4       Series 01 Episode 05 – The Hamburger Postulate        725\n",
       "..                                                 ...        ...\n",
       "226  Series 10 Episode 20 – The Recollection Dissip...        154\n",
       "227    Series 10 Episode 21 – The Separation Agitation        148\n",
       "228  Series 10 Episode 22 – The Cognition Regeneration        507\n",
       "229     Series 10 Episode 23 – The Gyroscopic Collapse        283\n",
       "230  Series 10 Episode 24 – The Long Distance Disso...        217\n",
       "\n",
       "[231 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words per episode\n",
    "words_per_episode = leonard_df.groupby('episode_name')['num_words'].sum().reset_index()\n",
    "words_per_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b595dc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435.6277056277056"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average words per episode \n",
    "avg_words_per_episode = words_per_episode['num_words'].mean()\n",
    "avg_words_per_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b17c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "leonard_df['season_nr'] = leonard_df['episode_name'].str.extract(r'Series (\\d+)')\n",
    "leonard_df['season_nr'] = leonard_df['season_nr'].astype(float)\n",
    "\n",
    "sentences_per_season_episode = leonard_df.groupby(['season_nr', 'episode_name'])['num_sentences'].sum().reset_index()\n",
    "words_per_season_episode = leonard_df.groupby(['season_nr', 'episode_name'])['num_words'].sum().reset_index()\n",
    "\n",
    "# Average sentences per season-episode\n",
    "avg_sentences_per_season = sentences_per_season_episode.groupby('season_nr')['num_sentences'].mean().reset_index()\n",
    "\n",
    "# Average words per season-episode\n",
    "avg_words_per_season = words_per_season_episode.groupby('season_nr')['num_words'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19da0a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Leonard's sentences per episode: 62\n",
      "Average Leonard's sentences per season-episode:    season_nr  num_sentences\n",
      "0        1.0           92.0\n",
      "1        2.0           79.0\n",
      "2        3.0           76.0\n",
      "3        4.0           67.0\n",
      "4        5.0           61.0\n",
      "5        6.0           53.0\n",
      "6        7.0           54.0\n",
      "7        8.0           54.0\n",
      "8        9.0           50.0\n",
      "9       10.0           44.0\n",
      "Average Leonard's words per episode: 436\n",
      "Average Leonard's words per season-episode:    season_nr  num_words\n",
      "0        1.0      712.0\n",
      "1        2.0      544.0\n",
      "2        3.0      509.0\n",
      "3        4.0      422.0\n",
      "4        5.0      420.0\n",
      "5        6.0      367.0\n",
      "6        7.0      389.0\n",
      "7        8.0      397.0\n",
      "8        9.0      352.0\n",
      "9       10.0      333.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Leonard's sentences per episode:\", round(avg_sentences_per_episode))\n",
    "print(\"Average Leonard's sentences per season-episode:\", round(avg_sentences_per_season))\n",
    "print(\"Average Leonard's words per episode:\", round(avg_words_per_episode))\n",
    "print(\"Average Leonard's words per season-episode:\", round(avg_words_per_season))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589e7a60",
   "metadata": {},
   "source": [
    "## Answer 1: \n",
    "In order to answer Question 1, we performed sentence and word tokenization, and removed the punctuation from the dialogues.\n",
    "\n",
    "On average, Leonard speaks around 62 sentences or 436 words per episode across all seasons. When looking at the average sentences and words for each season separately, the results indicate that these averages do deviate across seasons. More specifically, Leonard speaks less sentences and words per episode as each season goes by. In season 1, Leonard has an average of 92 sentences and 713 words. By season 10, his average number of sentences per episode has dropped to 44, and his average number of words has gone down to 333 words per episode. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea78c31",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Globally, over all episodes within the first 10 seasons, how many times does your\n",
    "character mention nouns, and person names? Make a Wordcloud of this tag/entity to\n",
    "have a clear visualization which nouns/person names are mostly used by your character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99a7c7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>person_scene</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>dialogue_no_punct</th>\n",
       "      <th>dialogue_no_punct_lower</th>\n",
       "      <th>num_words</th>\n",
       "      <th>season_nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Agreed  what s your point</td>\n",
       "      <td>agreed  what s your point</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Excuse me?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Excuse me</td>\n",
       "      <td>excuse me</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, ...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>3</td>\n",
       "      <td>One across is Aegean  eight down is Nabakov  ...</td>\n",
       "      <td>one across is aegean  eight down is nabakov  ...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Yes. Um, is this the High IQ sperm bank?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes  Um  is this the High IQ sperm bank</td>\n",
       "      <td>yes  um  is this the high iq sperm bank</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Thank-you. We’ll be right back.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Thank you  We ll be right back</td>\n",
       "      <td>thank you  we ll be right back</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            episode_name  \\\n",
       "2   Series 01 Episode 01 – Pilot Episode   \n",
       "4   Series 01 Episode 01 – Pilot Episode   \n",
       "6   Series 01 Episode 01 – Pilot Episode   \n",
       "8   Series 01 Episode 01 – Pilot Episode   \n",
       "12  Series 01 Episode 01 – Pilot Episode   \n",
       "\n",
       "                                             dialogue person_scene  \\\n",
       "2                          Agreed, what’s your point?      Leonard   \n",
       "4                                          Excuse me?      Leonard   \n",
       "6    One across is Aegean, eight down is Nabakov, ...      Leonard   \n",
       "8            Yes. Um, is this the High IQ sperm bank?      Leonard   \n",
       "12                    Thank-you. We’ll be right back.      Leonard   \n",
       "\n",
       "    num_sentences                                  dialogue_no_punct  \\\n",
       "2               1                         Agreed  what s your point    \n",
       "4               1                                         Excuse me    \n",
       "6               3   One across is Aegean  eight down is Nabakov  ...   \n",
       "8               2           Yes  Um  is this the High IQ sperm bank    \n",
       "12              2                    Thank you  We ll be right back    \n",
       "\n",
       "                              dialogue_no_punct_lower  num_words  season_nr  \n",
       "2                          agreed  what s your point           5        1.0  \n",
       "4                                          excuse me           2        1.0  \n",
       "6    one across is aegean  eight down is nabakov  ...         39        1.0  \n",
       "8            yes  um  is this the high iq sperm bank           9        1.0  \n",
       "12                    thank you  we ll be right back           7        1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase\n",
    "leonard_df['dialogue_no_punct_lower'] = leonard_df['dialogue_no_punct'].apply(lambda x: x.lower())\n",
    "\n",
    "leonard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e419089c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>person_scene</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>dialogue_no_punct</th>\n",
       "      <th>dialogue_no_punct_lower</th>\n",
       "      <th>num_words</th>\n",
       "      <th>season_nr</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Agreed  what s your point</td>\n",
       "      <td>agreed  what s your point</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[agreed, what, s, your, point]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Excuse me?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Excuse me</td>\n",
       "      <td>excuse me</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[excuse, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, ...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>3</td>\n",
       "      <td>One across is Aegean  eight down is Nabakov  ...</td>\n",
       "      <td>one across is aegean  eight down is nabakov  ...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[one, across, is, aegean, eight, down, is, nab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Yes. Um, is this the High IQ sperm bank?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes  Um  is this the High IQ sperm bank</td>\n",
       "      <td>yes  um  is this the high iq sperm bank</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[yes, um, is, this, the, high, iq, sperm, bank]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Thank-you. We’ll be right back.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Thank you  We ll be right back</td>\n",
       "      <td>thank you  we ll be right back</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[thank, you, we, ll, be, right, back]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            episode_name  \\\n",
       "2   Series 01 Episode 01 – Pilot Episode   \n",
       "4   Series 01 Episode 01 – Pilot Episode   \n",
       "6   Series 01 Episode 01 – Pilot Episode   \n",
       "8   Series 01 Episode 01 – Pilot Episode   \n",
       "12  Series 01 Episode 01 – Pilot Episode   \n",
       "\n",
       "                                             dialogue person_scene  \\\n",
       "2                          Agreed, what’s your point?      Leonard   \n",
       "4                                          Excuse me?      Leonard   \n",
       "6    One across is Aegean, eight down is Nabakov, ...      Leonard   \n",
       "8            Yes. Um, is this the High IQ sperm bank?      Leonard   \n",
       "12                    Thank-you. We’ll be right back.      Leonard   \n",
       "\n",
       "    num_sentences                                  dialogue_no_punct  \\\n",
       "2               1                         Agreed  what s your point    \n",
       "4               1                                         Excuse me    \n",
       "6               3   One across is Aegean  eight down is Nabakov  ...   \n",
       "8               2           Yes  Um  is this the High IQ sperm bank    \n",
       "12              2                    Thank you  We ll be right back    \n",
       "\n",
       "                              dialogue_no_punct_lower  num_words  season_nr  \\\n",
       "2                          agreed  what s your point           5        1.0   \n",
       "4                                          excuse me           2        1.0   \n",
       "6    one across is aegean  eight down is nabakov  ...         39        1.0   \n",
       "8            yes  um  is this the high iq sperm bank           9        1.0   \n",
       "12                    thank you  we ll be right back           7        1.0   \n",
       "\n",
       "                                               tokens  \n",
       "2                      [agreed, what, s, your, point]  \n",
       "4                                        [excuse, me]  \n",
       "6   [one, across, is, aegean, eight, down, is, nab...  \n",
       "8     [yes, um, is, this, the, high, iq, sperm, bank]  \n",
       "12              [thank, you, we, ll, be, right, back]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word tokenization \n",
    "leonard_df['tokens'] = leonard_df['dialogue_no_punct_lower'].apply(word_tokenize)\n",
    "leonard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "561a503d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>person_scene</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>dialogue_no_punct</th>\n",
       "      <th>dialogue_no_punct_lower</th>\n",
       "      <th>num_words</th>\n",
       "      <th>season_nr</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_no_stop</th>\n",
       "      <th>dialogue_no_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Agreed  what s your point</td>\n",
       "      <td>agreed  what s your point</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[agreed, what, s, your, point]</td>\n",
       "      <td>[agreed, point]</td>\n",
       "      <td>agreed point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Excuse me?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Excuse me</td>\n",
       "      <td>excuse me</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[excuse, me]</td>\n",
       "      <td>[excuse]</td>\n",
       "      <td>excuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, ...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>3</td>\n",
       "      <td>One across is Aegean  eight down is Nabakov  ...</td>\n",
       "      <td>one across is aegean  eight down is nabakov  ...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[one, across, is, aegean, eight, down, is, nab...</td>\n",
       "      <td>[one, across, aegean, eight, nabakov, twenty, ...</td>\n",
       "      <td>one across aegean eight nabakov twenty six acr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Yes. Um, is this the High IQ sperm bank?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes  Um  is this the High IQ sperm bank</td>\n",
       "      <td>yes  um  is this the high iq sperm bank</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[yes, um, is, this, the, high, iq, sperm, bank]</td>\n",
       "      <td>[yes, um, high, iq, sperm, bank]</td>\n",
       "      <td>yes um high iq sperm bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Thank-you. We’ll be right back.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Thank you  We ll be right back</td>\n",
       "      <td>thank you  we ll be right back</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[thank, you, we, ll, be, right, back]</td>\n",
       "      <td>[thank, right, back]</td>\n",
       "      <td>thank right back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            episode_name  \\\n",
       "2   Series 01 Episode 01 – Pilot Episode   \n",
       "4   Series 01 Episode 01 – Pilot Episode   \n",
       "6   Series 01 Episode 01 – Pilot Episode   \n",
       "8   Series 01 Episode 01 – Pilot Episode   \n",
       "12  Series 01 Episode 01 – Pilot Episode   \n",
       "\n",
       "                                             dialogue person_scene  \\\n",
       "2                          Agreed, what’s your point?      Leonard   \n",
       "4                                          Excuse me?      Leonard   \n",
       "6    One across is Aegean, eight down is Nabakov, ...      Leonard   \n",
       "8            Yes. Um, is this the High IQ sperm bank?      Leonard   \n",
       "12                    Thank-you. We’ll be right back.      Leonard   \n",
       "\n",
       "    num_sentences                                  dialogue_no_punct  \\\n",
       "2               1                         Agreed  what s your point    \n",
       "4               1                                         Excuse me    \n",
       "6               3   One across is Aegean  eight down is Nabakov  ...   \n",
       "8               2           Yes  Um  is this the High IQ sperm bank    \n",
       "12              2                    Thank you  We ll be right back    \n",
       "\n",
       "                              dialogue_no_punct_lower  num_words  season_nr  \\\n",
       "2                          agreed  what s your point           5        1.0   \n",
       "4                                          excuse me           2        1.0   \n",
       "6    one across is aegean  eight down is nabakov  ...         39        1.0   \n",
       "8            yes  um  is this the high iq sperm bank           9        1.0   \n",
       "12                    thank you  we ll be right back           7        1.0   \n",
       "\n",
       "                                               tokens  \\\n",
       "2                      [agreed, what, s, your, point]   \n",
       "4                                        [excuse, me]   \n",
       "6   [one, across, is, aegean, eight, down, is, nab...   \n",
       "8     [yes, um, is, this, the, high, iq, sperm, bank]   \n",
       "12              [thank, you, we, ll, be, right, back]   \n",
       "\n",
       "                                       tokens_no_stop  \\\n",
       "2                                     [agreed, point]   \n",
       "4                                            [excuse]   \n",
       "6   [one, across, aegean, eight, nabakov, twenty, ...   \n",
       "8                    [yes, um, high, iq, sperm, bank]   \n",
       "12                               [thank, right, back]   \n",
       "\n",
       "                                     dialogue_no_stop  \n",
       "2                                        agreed point  \n",
       "4                                              excuse  \n",
       "6   one across aegean eight nabakov twenty six acr...  \n",
       "8                           yes um high iq sperm bank  \n",
       "12                                   thank right back  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    " \n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "leonard_df['tokens_no_stop'] = leonard_df['tokens'].apply(remove_stopwords) \n",
    "leonard_df['dialogue_no_stop'] = leonard_df['tokens_no_stop'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "leonard_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60877a52",
   "metadata": {},
   "source": [
    "We can see that there are still some stopwords in the dialogues, such as 'um'. These are manually removed by adding them to the stopwords list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d228845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae0de5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>person_scene</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>dialogue_no_punct</th>\n",
       "      <th>dialogue_no_punct_lower</th>\n",
       "      <th>num_words</th>\n",
       "      <th>season_nr</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_no_stop</th>\n",
       "      <th>dialogue_no_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Agreed, what’s your point?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Agreed  what s your point</td>\n",
       "      <td>agreed  what s your point</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[agreed, what, s, your, point]</td>\n",
       "      <td>[agreed, point]</td>\n",
       "      <td>agreed point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Excuse me?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Excuse me</td>\n",
       "      <td>excuse me</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[excuse, me]</td>\n",
       "      <td>[excuse]</td>\n",
       "      <td>excuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>One across is Aegean, eight down is Nabakov, ...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>3</td>\n",
       "      <td>One across is Aegean  eight down is Nabakov  ...</td>\n",
       "      <td>one across is aegean  eight down is nabakov  ...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[one, across, is, aegean, eight, down, is, nab...</td>\n",
       "      <td>[one, across, aegean, eight, nabakov, twenty, ...</td>\n",
       "      <td>one across aegean eight nabakov twenty six acr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Yes. Um, is this the High IQ sperm bank?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes  Um  is this the High IQ sperm bank</td>\n",
       "      <td>yes  um  is this the high iq sperm bank</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[yes, um, is, this, the, high, iq, sperm, bank]</td>\n",
       "      <td>[high, iq, sperm, bank]</td>\n",
       "      <td>high iq sperm bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Thank-you. We’ll be right back.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Thank you  We ll be right back</td>\n",
       "      <td>thank you  we ll be right back</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[thank, you, we, ll, be, right, back]</td>\n",
       "      <td>[thank, right, back]</td>\n",
       "      <td>thank right back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>What, are you kidding? You’re a semi-pro.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>What  are you kidding  You re a semi pro</td>\n",
       "      <td>what  are you kidding  you re a semi pro</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[what, are, you, kidding, you, re, a, semi, pro]</td>\n",
       "      <td>[kidding, semi, pro]</td>\n",
       "      <td>kidding semi pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Sheldon, this was your idea. A little extra m...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Sheldon  this was your idea  A little extra m...</td>\n",
       "      <td>sheldon  this was your idea  a little extra m...</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[sheldon, this, was, your, idea, a, little, ex...</td>\n",
       "      <td>[sheldon, idea, little, extra, money, get, fra...</td>\n",
       "      <td>sheldon idea little extra money get fractional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I’m sure she’ll still love him.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>I m sure she ll still love him</td>\n",
       "      <td>i m sure she ll still love him</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, m, sure, she, ll, still, love, him]</td>\n",
       "      <td>[sure, still, love]</td>\n",
       "      <td>sure still love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Well, what do you want to do?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Well  what do you want to do</td>\n",
       "      <td>well  what do you want to do</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[well, what, do, you, want, to, do]</td>\n",
       "      <td>[want]</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[okay]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I don’t know, I’ve never reneged on a proffer...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>I don t know  I ve never reneged on a proffer...</td>\n",
       "      <td>i don t know  i ve never reneged on a proffer...</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, don, t, know, i, ve, never, reneged, on, a...</td>\n",
       "      <td>[know, never, reneged, proffer, sperm]</td>\n",
       "      <td>know never reneged proffer sperm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Okay</td>\n",
       "      <td>okay</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[okay]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>See you.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>See you</td>\n",
       "      <td>see you</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[see, you]</td>\n",
       "      <td>[see]</td>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>No.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[no]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Not really.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Not really</td>\n",
       "      <td>not really</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[not, really]</td>\n",
       "      <td>[really]</td>\n",
       "      <td>really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I don’t care. Two millimetres? That doesn’t se...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>3</td>\n",
       "      <td>I don t care  Two millimetres  That doesn t se...</td>\n",
       "      <td>i don t care  two millimetres  that doesn t se...</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, don, t, care, two, millimetres, that, does...</td>\n",
       "      <td>[care, two, millimetres, seem, right]</td>\n",
       "      <td>care two millimetres seem right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Is that why they sent you to boarding school?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Is that why they sent you to boarding school</td>\n",
       "      <td>is that why they sent you to boarding school</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[is, that, why, they, sent, you, to, boarding,...</td>\n",
       "      <td>[sent, boarding, school]</td>\n",
       "      <td>sent boarding school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>New neighbour?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>New neighbour</td>\n",
       "      <td>new neighbour</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[new, neighbour]</td>\n",
       "      <td>[new, neighbour]</td>\n",
       "      <td>new neighbour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Significant improvement over the old neighbour.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Significant improvement over the old neighbour</td>\n",
       "      <td>significant improvement over the old neighbour</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[significant, improvement, over, the, old, nei...</td>\n",
       "      <td>[significant, improvement, old, neighbour]</td>\n",
       "      <td>significant improvement old neighbour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi</td>\n",
       "      <td>hi</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi</td>\n",
       "      <td>hi</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>We don’t mean to interrupt, we live across th...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>We don t mean to interrupt  we live across th...</td>\n",
       "      <td>we don t mean to interrupt  we live across th...</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[we, don, t, mean, to, interrupt, we, live, ac...</td>\n",
       "      <td>[mean, interrupt, live, across, hall]</td>\n",
       "      <td>mean interrupt live across hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Oh… uh… no… we don’t live together… um… we li...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh  uh  no  we don t live together  um  we li...</td>\n",
       "      <td>oh  uh  no  we don t live together  um  we li...</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[oh, uh, no, we, don, t, live, together, um, w...</td>\n",
       "      <td>[live, together, live, together, separate, het...</td>\n",
       "      <td>live together live together separate heterosex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Leonard, Sheldon.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Leonard  Sheldon</td>\n",
       "      <td>leonard  sheldon</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[leonard, sheldon]</td>\n",
       "      <td>[leonard, sheldon]</td>\n",
       "      <td>leonard sheldon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi</td>\n",
       "      <td>hi</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi. Well, uh, oh, welcome to the building.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Hi  Well  uh  oh  welcome to the building</td>\n",
       "      <td>hi  well  uh  oh  welcome to the building</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[hi, well, uh, oh, welcome, to, the, building]</td>\n",
       "      <td>[hi, welcome, building]</td>\n",
       "      <td>hi welcome building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Oh, great.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh  great</td>\n",
       "      <td>oh  great</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[oh, great]</td>\n",
       "      <td>[great]</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Great. Well, bye.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Great  Well  bye</td>\n",
       "      <td>great  well  bye</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[great, well, bye]</td>\n",
       "      <td>[great, bye]</td>\n",
       "      <td>great bye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Bye.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Bye</td>\n",
       "      <td>bye</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[bye]</td>\n",
       "      <td>[bye]</td>\n",
       "      <td>bye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Should we have invited her for lunch?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Should we have invited her for lunch</td>\n",
       "      <td>should we have invited her for lunch</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[should, we, have, invited, her, for, lunch]</td>\n",
       "      <td>[invited, lunch]</td>\n",
       "      <td>invited lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>We already watched the Season Two DVDs.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>We already watched the Season Two DVDs</td>\n",
       "      <td>we already watched the season two dvds</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[we, already, watched, the, season, two, dvds]</td>\n",
       "      <td>[already, watched, season, two, dvds]</td>\n",
       "      <td>already watched season two dvds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I think we should be good neighbours, invite ...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>I think we should be good neighbours  invite ...</td>\n",
       "      <td>i think we should be good neighbours  invite ...</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, think, we, should, be, good, neighbours, i...</td>\n",
       "      <td>[think, good, neighbours, invite, make, feel, ...</td>\n",
       "      <td>think good neighbours invite make feel welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Well, then that was wrong of us. We need to w...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Well  then that was wrong of us  We need to w...</td>\n",
       "      <td>well  then that was wrong of us  we need to w...</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[well, then, that, was, wrong, of, us, we, nee...</td>\n",
       "      <td>[wrong, us, need, widen, circle]</td>\n",
       "      <td>wrong us need widen circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Yes, and you’ve never met one of them.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes  and you ve never met one of them</td>\n",
       "      <td>yes  and you ve never met one of them</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[yes, and, you, ve, never, met, one, of, them]</td>\n",
       "      <td>[never, met, one]</td>\n",
       "      <td>never met one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I’m going to invite her over. We’ll have a nic...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>I m going to invite her over  We ll have a nic...</td>\n",
       "      <td>i m going to invite her over  we ll have a nic...</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, m, going, to, invite, her, over, we, ll, h...</td>\n",
       "      <td>[going, invite, nice, meal, chat]</td>\n",
       "      <td>going invite nice meal chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Well it’s not difficult, you just listen to w...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Well it s not difficult  you just listen to w...</td>\n",
       "      <td>well it s not difficult  you just listen to w...</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[well, it, s, not, difficult, you, just, liste...</td>\n",
       "      <td>[difficult, listen, says, say, something, appr...</td>\n",
       "      <td>difficult listen says say something appropriat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi. Again.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>Hi  Again</td>\n",
       "      <td>hi  again</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[hi, again]</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi</td>\n",
       "      <td>hi</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>[hi]</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Anyway, um. We brought home Indian food. And,...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>5</td>\n",
       "      <td>Anyway  um  We brought home Indian food  And ...</td>\n",
       "      <td>anyway  um  we brought home indian food  and ...</td>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[anyway, um, we, brought, home, indian, food, ...</td>\n",
       "      <td>[anyway, brought, home, indian, food, know, mo...</td>\n",
       "      <td>anyway brought home indian food know moving st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Uh, yes.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Uh  yes</td>\n",
       "      <td>uh  yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[uh, yes]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Great.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Great</td>\n",
       "      <td>great</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[great]</td>\n",
       "      <td>[great]</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Okay, well, make yourself at home.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Okay  well  make yourself at home</td>\n",
       "      <td>okay  well  make yourself at home</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[okay, well, make, yourself, at, home]</td>\n",
       "      <td>[make, home]</td>\n",
       "      <td>make home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>You’re very welcome.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>You re very welcome</td>\n",
       "      <td>you re very welcome</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[you, re, very, welcome]</td>\n",
       "      <td>[welcome]</td>\n",
       "      <td>welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>I have a board. If you like boards, this is m...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>2</td>\n",
       "      <td>I have a board  If you like boards  this is m...</td>\n",
       "      <td>i have a board  if you like boards  this is m...</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[i, have, a, board, if, you, like, boards, thi...</td>\n",
       "      <td>[board, like, boards, board]</td>\n",
       "      <td>board like boards board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>What?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>What</td>\n",
       "      <td>what</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[what]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>At least I didn’t have to invent twenty-six di...</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>At least I didn t have to invent twenty six di...</td>\n",
       "      <td>at least i didn t have to invent twenty six di...</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[at, least, i, didn, t, have, to, invent, twen...</td>\n",
       "      <td>[least, invent, twenty, six, dimensions, make,...</td>\n",
       "      <td>least invent twenty six dimensions make math come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>In what universe?</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>In what universe</td>\n",
       "      <td>in what universe</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[in, what, universe]</td>\n",
       "      <td>[universe]</td>\n",
       "      <td>universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Here we go.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Here we go</td>\n",
       "      <td>here we go</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[here, we, go]</td>\n",
       "      <td>[go]</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Just sit somewhere else.</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Just sit somewhere else</td>\n",
       "      <td>just sit somewhere else</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[just, sit, somewhere, else]</td>\n",
       "      <td>[sit, somewhere, else]</td>\n",
       "      <td>sit somewhere else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Series 01 Episode 01 – Pilot Episode</td>\n",
       "      <td>Sheldon, sit!</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheldon  sit</td>\n",
       "      <td>sheldon  sit</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[sheldon, sit]</td>\n",
       "      <td>[sheldon, sit]</td>\n",
       "      <td>sheldon sit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             episode_name  \\\n",
       "2    Series 01 Episode 01 – Pilot Episode   \n",
       "4    Series 01 Episode 01 – Pilot Episode   \n",
       "6    Series 01 Episode 01 – Pilot Episode   \n",
       "8    Series 01 Episode 01 – Pilot Episode   \n",
       "12   Series 01 Episode 01 – Pilot Episode   \n",
       "15   Series 01 Episode 01 – Pilot Episode   \n",
       "17   Series 01 Episode 01 – Pilot Episode   \n",
       "19   Series 01 Episode 01 – Pilot Episode   \n",
       "21   Series 01 Episode 01 – Pilot Episode   \n",
       "23   Series 01 Episode 01 – Pilot Episode   \n",
       "25   Series 01 Episode 01 – Pilot Episode   \n",
       "27   Series 01 Episode 01 – Pilot Episode   \n",
       "29   Series 01 Episode 01 – Pilot Episode   \n",
       "32   Series 01 Episode 01 – Pilot Episode   \n",
       "34   Series 01 Episode 01 – Pilot Episode   \n",
       "36   Series 01 Episode 01 – Pilot Episode   \n",
       "38   Series 01 Episode 01 – Pilot Episode   \n",
       "40   Series 01 Episode 01 – Pilot Episode   \n",
       "42   Series 01 Episode 01 – Pilot Episode   \n",
       "45   Series 01 Episode 01 – Pilot Episode   \n",
       "47   Series 01 Episode 01 – Pilot Episode   \n",
       "50   Series 01 Episode 01 – Pilot Episode   \n",
       "52   Series 01 Episode 01 – Pilot Episode   \n",
       "54   Series 01 Episode 01 – Pilot Episode   \n",
       "56   Series 01 Episode 01 – Pilot Episode   \n",
       "59   Series 01 Episode 01 – Pilot Episode   \n",
       "61   Series 01 Episode 01 – Pilot Episode   \n",
       "64   Series 01 Episode 01 – Pilot Episode   \n",
       "67   Series 01 Episode 01 – Pilot Episode   \n",
       "68   Series 01 Episode 01 – Pilot Episode   \n",
       "70   Series 01 Episode 01 – Pilot Episode   \n",
       "72   Series 01 Episode 01 – Pilot Episode   \n",
       "74   Series 01 Episode 01 – Pilot Episode   \n",
       "76   Series 01 Episode 01 – Pilot Episode   \n",
       "78   Series 01 Episode 01 – Pilot Episode   \n",
       "80   Series 01 Episode 01 – Pilot Episode   \n",
       "82   Series 01 Episode 01 – Pilot Episode   \n",
       "85   Series 01 Episode 01 – Pilot Episode   \n",
       "87   Series 01 Episode 01 – Pilot Episode   \n",
       "90   Series 01 Episode 01 – Pilot Episode   \n",
       "92   Series 01 Episode 01 – Pilot Episode   \n",
       "96   Series 01 Episode 01 – Pilot Episode   \n",
       "98   Series 01 Episode 01 – Pilot Episode   \n",
       "106  Series 01 Episode 01 – Pilot Episode   \n",
       "109  Series 01 Episode 01 – Pilot Episode   \n",
       "111  Series 01 Episode 01 – Pilot Episode   \n",
       "113  Series 01 Episode 01 – Pilot Episode   \n",
       "121  Series 01 Episode 01 – Pilot Episode   \n",
       "125  Series 01 Episode 01 – Pilot Episode   \n",
       "127  Series 01 Episode 01 – Pilot Episode   \n",
       "\n",
       "                                              dialogue person_scene  \\\n",
       "2                           Agreed, what’s your point?      Leonard   \n",
       "4                                           Excuse me?      Leonard   \n",
       "6     One across is Aegean, eight down is Nabakov, ...      Leonard   \n",
       "8             Yes. Um, is this the High IQ sperm bank?      Leonard   \n",
       "12                     Thank-you. We’ll be right back.      Leonard   \n",
       "15          What, are you kidding? You’re a semi-pro.       Leonard   \n",
       "17    Sheldon, this was your idea. A little extra m...      Leonard   \n",
       "19                     I’m sure she’ll still love him.      Leonard   \n",
       "21                       Well, what do you want to do?      Leonard   \n",
       "23                                               Okay.      Leonard   \n",
       "25    I don’t know, I’ve never reneged on a proffer...      Leonard   \n",
       "27                                               Okay.      Leonard   \n",
       "29                                            See you.      Leonard   \n",
       "32                                                 No.      Leonard   \n",
       "34                                         Not really.      Leonard   \n",
       "36   I don’t care. Two millimetres? That doesn’t se...      Leonard   \n",
       "38       Is that why they sent you to boarding school?      Leonard   \n",
       "40                                      New neighbour?      Leonard   \n",
       "42     Significant improvement over the old neighbour.      Leonard   \n",
       "45                                                 Hi.      Leonard   \n",
       "47                                                 Hi.      Leonard   \n",
       "50    We don’t mean to interrupt, we live across th...      Leonard   \n",
       "52    Oh… uh… no… we don’t live together… um… we li...      Leonard   \n",
       "54                                   Leonard, Sheldon.      Leonard   \n",
       "56                                                 Hi.      Leonard   \n",
       "59          Hi. Well, uh, oh, welcome to the building.      Leonard   \n",
       "61                                          Oh, great.      Leonard   \n",
       "64                                   Great. Well, bye.      Leonard   \n",
       "67                                               Bye.       Leonard   \n",
       "68               Should we have invited her for lunch?      Leonard   \n",
       "70             We already watched the Season Two DVDs.      Leonard   \n",
       "72    I think we should be good neighbours, invite ...      Leonard   \n",
       "74    Well, then that was wrong of us. We need to w...      Leonard   \n",
       "76              Yes, and you’ve never met one of them.      Leonard   \n",
       "78   I’m going to invite her over. We’ll have a nic...      Leonard   \n",
       "80    Well it’s not difficult, you just listen to w...      Leonard   \n",
       "82                                          Hi. Again.      Leonard   \n",
       "85                                                 Hi.      Leonard   \n",
       "87    Anyway, um. We brought home Indian food. And,...      Leonard   \n",
       "90                                            Uh, yes.      Leonard   \n",
       "92                                              Great.      Leonard   \n",
       "96                  Okay, well, make yourself at home.      Leonard   \n",
       "98                                You’re very welcome.      Leonard   \n",
       "106   I have a board. If you like boards, this is m...      Leonard   \n",
       "109                                              What?      Leonard   \n",
       "111  At least I didn’t have to invent twenty-six di...      Leonard   \n",
       "113                                  In what universe?      Leonard   \n",
       "121                                        Here we go.      Leonard   \n",
       "125                           Just sit somewhere else.      Leonard   \n",
       "127                                      Sheldon, sit!      Leonard   \n",
       "\n",
       "     num_sentences                                  dialogue_no_punct  \\\n",
       "2                1                         Agreed  what s your point    \n",
       "4                1                                         Excuse me    \n",
       "6                3   One across is Aegean  eight down is Nabakov  ...   \n",
       "8                2           Yes  Um  is this the High IQ sperm bank    \n",
       "12               2                    Thank you  We ll be right back    \n",
       "15               2         What  are you kidding  You re a semi pro     \n",
       "17               2   Sheldon  this was your idea  A little extra m...   \n",
       "19               1                    I m sure she ll still love him    \n",
       "21               1                      Well  what do you want to do    \n",
       "23               1                                              Okay    \n",
       "25               1   I don t know  I ve never reneged on a proffer...   \n",
       "27               1                                              Okay    \n",
       "29               1                                           See you    \n",
       "32               1                                                No    \n",
       "34               1                                        Not really    \n",
       "36               3  I don t care  Two millimetres  That doesn t se...   \n",
       "38               1      Is that why they sent you to boarding school    \n",
       "40               1                                     New neighbour    \n",
       "42               1    Significant improvement over the old neighbour    \n",
       "45               1                                                Hi    \n",
       "47               1                                                Hi    \n",
       "50               1   We don t mean to interrupt  we live across th...   \n",
       "52               1   Oh  uh  no  we don t live together  um  we li...   \n",
       "54               1                                  Leonard  Sheldon    \n",
       "56               1                                                Hi    \n",
       "59               2         Hi  Well  uh  oh  welcome to the building    \n",
       "61               1                                         Oh  great    \n",
       "64               2                                  Great  Well  bye    \n",
       "67               1                                              Bye     \n",
       "68               1              Should we have invited her for lunch    \n",
       "70               1            We already watched the Season Two DVDs    \n",
       "72               1   I think we should be good neighbours  invite ...   \n",
       "74               2   Well  then that was wrong of us  We need to w...   \n",
       "76               1             Yes  and you ve never met one of them    \n",
       "78               2  I m going to invite her over  We ll have a nic...   \n",
       "80               1   Well it s not difficult  you just listen to w...   \n",
       "82               2                                         Hi  Again    \n",
       "85               1                                                Hi    \n",
       "87               5   Anyway  um  We brought home Indian food  And ...   \n",
       "90               1                                           Uh  yes    \n",
       "92               1                                             Great    \n",
       "96               1                 Okay  well  make yourself at home    \n",
       "98               1                               You re very welcome    \n",
       "106              2   I have a board  If you like boards  this is m...   \n",
       "109              1                                              What    \n",
       "111              1  At least I didn t have to invent twenty six di...   \n",
       "113              1                                  In what universe    \n",
       "121              1                                        Here we go    \n",
       "125              1                           Just sit somewhere else    \n",
       "127              1                                      Sheldon  sit    \n",
       "\n",
       "                               dialogue_no_punct_lower  num_words  season_nr  \\\n",
       "2                           agreed  what s your point           5        1.0   \n",
       "4                                           excuse me           2        1.0   \n",
       "6     one across is aegean  eight down is nabakov  ...         39        1.0   \n",
       "8             yes  um  is this the high iq sperm bank           9        1.0   \n",
       "12                     thank you  we ll be right back           7        1.0   \n",
       "15          what  are you kidding  you re a semi pro            9        1.0   \n",
       "17    sheldon  this was your idea  a little extra m...         17        1.0   \n",
       "19                     i m sure she ll still love him           8        1.0   \n",
       "21                       well  what do you want to do           7        1.0   \n",
       "23                                               okay           1        1.0   \n",
       "25    i don t know  i ve never reneged on a proffer...         14        1.0   \n",
       "27                                               okay           1        1.0   \n",
       "29                                            see you           2        1.0   \n",
       "32                                                 no           1        1.0   \n",
       "34                                         not really           2        1.0   \n",
       "36   i don t care  two millimetres  that doesn t se...         11        1.0   \n",
       "38       is that why they sent you to boarding school           9        1.0   \n",
       "40                                      new neighbour           2        1.0   \n",
       "42     significant improvement over the old neighbour           6        1.0   \n",
       "45                                                 hi           1        1.0   \n",
       "47                                                 hi           1        1.0   \n",
       "50    we don t mean to interrupt  we live across th...         11        1.0   \n",
       "52    oh  uh  no  we don t live together  um  we li...         17        1.0   \n",
       "54                                   leonard  sheldon           2        1.0   \n",
       "56                                                 hi           1        1.0   \n",
       "59          hi  well  uh  oh  welcome to the building           8        1.0   \n",
       "61                                          oh  great           2        1.0   \n",
       "64                                   great  well  bye           3        1.0   \n",
       "67                                               bye            1        1.0   \n",
       "68               should we have invited her for lunch           7        1.0   \n",
       "70             we already watched the season two dvds           7        1.0   \n",
       "72    i think we should be good neighbours  invite ...         14        1.0   \n",
       "74    well  then that was wrong of us  we need to w...         13        1.0   \n",
       "76              yes  and you ve never met one of them           9        1.0   \n",
       "78   i m going to invite her over  we ll have a nic...         15        1.0   \n",
       "80    well it s not difficult  you just listen to w...         20        1.0   \n",
       "82                                          hi  again           2        1.0   \n",
       "85                                                 hi           1        1.0   \n",
       "87    anyway  um  we brought home indian food  and ...         62        1.0   \n",
       "90                                            uh  yes           2        1.0   \n",
       "92                                              great           1        1.0   \n",
       "96                  okay  well  make yourself at home           6        1.0   \n",
       "98                                you re very welcome           4        1.0   \n",
       "106   i have a board  if you like boards  this is m...         12        1.0   \n",
       "109                                              what           1        1.0   \n",
       "111  at least i didn t have to invent twenty six di...         18        1.0   \n",
       "113                                  in what universe           3        1.0   \n",
       "121                                        here we go           3        1.0   \n",
       "125                           just sit somewhere else           4        1.0   \n",
       "127                                      sheldon  sit           2        1.0   \n",
       "\n",
       "                                                tokens  \\\n",
       "2                       [agreed, what, s, your, point]   \n",
       "4                                         [excuse, me]   \n",
       "6    [one, across, is, aegean, eight, down, is, nab...   \n",
       "8      [yes, um, is, this, the, high, iq, sperm, bank]   \n",
       "12               [thank, you, we, ll, be, right, back]   \n",
       "15    [what, are, you, kidding, you, re, a, semi, pro]   \n",
       "17   [sheldon, this, was, your, idea, a, little, ex...   \n",
       "19             [i, m, sure, she, ll, still, love, him]   \n",
       "21                 [well, what, do, you, want, to, do]   \n",
       "23                                              [okay]   \n",
       "25   [i, don, t, know, i, ve, never, reneged, on, a...   \n",
       "27                                              [okay]   \n",
       "29                                          [see, you]   \n",
       "32                                                [no]   \n",
       "34                                       [not, really]   \n",
       "36   [i, don, t, care, two, millimetres, that, does...   \n",
       "38   [is, that, why, they, sent, you, to, boarding,...   \n",
       "40                                    [new, neighbour]   \n",
       "42   [significant, improvement, over, the, old, nei...   \n",
       "45                                                [hi]   \n",
       "47                                                [hi]   \n",
       "50   [we, don, t, mean, to, interrupt, we, live, ac...   \n",
       "52   [oh, uh, no, we, don, t, live, together, um, w...   \n",
       "54                                  [leonard, sheldon]   \n",
       "56                                                [hi]   \n",
       "59      [hi, well, uh, oh, welcome, to, the, building]   \n",
       "61                                         [oh, great]   \n",
       "64                                  [great, well, bye]   \n",
       "67                                               [bye]   \n",
       "68        [should, we, have, invited, her, for, lunch]   \n",
       "70      [we, already, watched, the, season, two, dvds]   \n",
       "72   [i, think, we, should, be, good, neighbours, i...   \n",
       "74   [well, then, that, was, wrong, of, us, we, nee...   \n",
       "76      [yes, and, you, ve, never, met, one, of, them]   \n",
       "78   [i, m, going, to, invite, her, over, we, ll, h...   \n",
       "80   [well, it, s, not, difficult, you, just, liste...   \n",
       "82                                         [hi, again]   \n",
       "85                                                [hi]   \n",
       "87   [anyway, um, we, brought, home, indian, food, ...   \n",
       "90                                           [uh, yes]   \n",
       "92                                             [great]   \n",
       "96              [okay, well, make, yourself, at, home]   \n",
       "98                            [you, re, very, welcome]   \n",
       "106  [i, have, a, board, if, you, like, boards, thi...   \n",
       "109                                             [what]   \n",
       "111  [at, least, i, didn, t, have, to, invent, twen...   \n",
       "113                               [in, what, universe]   \n",
       "121                                     [here, we, go]   \n",
       "125                       [just, sit, somewhere, else]   \n",
       "127                                     [sheldon, sit]   \n",
       "\n",
       "                                        tokens_no_stop  \\\n",
       "2                                      [agreed, point]   \n",
       "4                                             [excuse]   \n",
       "6    [one, across, aegean, eight, nabakov, twenty, ...   \n",
       "8                              [high, iq, sperm, bank]   \n",
       "12                                [thank, right, back]   \n",
       "15                                [kidding, semi, pro]   \n",
       "17   [sheldon, idea, little, extra, money, get, fra...   \n",
       "19                                 [sure, still, love]   \n",
       "21                                              [want]   \n",
       "23                                                  []   \n",
       "25              [know, never, reneged, proffer, sperm]   \n",
       "27                                                  []   \n",
       "29                                               [see]   \n",
       "32                                                  []   \n",
       "34                                            [really]   \n",
       "36               [care, two, millimetres, seem, right]   \n",
       "38                            [sent, boarding, school]   \n",
       "40                                    [new, neighbour]   \n",
       "42          [significant, improvement, old, neighbour]   \n",
       "45                                                [hi]   \n",
       "47                                                [hi]   \n",
       "50               [mean, interrupt, live, across, hall]   \n",
       "52   [live, together, live, together, separate, het...   \n",
       "54                                  [leonard, sheldon]   \n",
       "56                                                [hi]   \n",
       "59                             [hi, welcome, building]   \n",
       "61                                             [great]   \n",
       "64                                        [great, bye]   \n",
       "67                                               [bye]   \n",
       "68                                    [invited, lunch]   \n",
       "70               [already, watched, season, two, dvds]   \n",
       "72   [think, good, neighbours, invite, make, feel, ...   \n",
       "74                    [wrong, us, need, widen, circle]   \n",
       "76                                   [never, met, one]   \n",
       "78                   [going, invite, nice, meal, chat]   \n",
       "80   [difficult, listen, says, say, something, appr...   \n",
       "82                                                [hi]   \n",
       "85                                                [hi]   \n",
       "87   [anyway, brought, home, indian, food, know, mo...   \n",
       "90                                                  []   \n",
       "92                                             [great]   \n",
       "96                                        [make, home]   \n",
       "98                                           [welcome]   \n",
       "106                       [board, like, boards, board]   \n",
       "109                                                 []   \n",
       "111  [least, invent, twenty, six, dimensions, make,...   \n",
       "113                                         [universe]   \n",
       "121                                               [go]   \n",
       "125                             [sit, somewhere, else]   \n",
       "127                                     [sheldon, sit]   \n",
       "\n",
       "                                      dialogue_no_stop  \n",
       "2                                         agreed point  \n",
       "4                                               excuse  \n",
       "6    one across aegean eight nabakov twenty six acr...  \n",
       "8                                   high iq sperm bank  \n",
       "12                                    thank right back  \n",
       "15                                    kidding semi pro  \n",
       "17   sheldon idea little extra money get fractional...  \n",
       "19                                     sure still love  \n",
       "21                                                want  \n",
       "23                                                      \n",
       "25                    know never reneged proffer sperm  \n",
       "27                                                      \n",
       "29                                                 see  \n",
       "32                                                      \n",
       "34                                              really  \n",
       "36                     care two millimetres seem right  \n",
       "38                                sent boarding school  \n",
       "40                                       new neighbour  \n",
       "42               significant improvement old neighbour  \n",
       "45                                                  hi  \n",
       "47                                                  hi  \n",
       "50                     mean interrupt live across hall  \n",
       "52   live together live together separate heterosex...  \n",
       "54                                     leonard sheldon  \n",
       "56                                                  hi  \n",
       "59                                 hi welcome building  \n",
       "61                                               great  \n",
       "64                                           great bye  \n",
       "67                                                 bye  \n",
       "68                                       invited lunch  \n",
       "70                     already watched season two dvds  \n",
       "72      think good neighbours invite make feel welcome  \n",
       "74                          wrong us need widen circle  \n",
       "76                                       never met one  \n",
       "78                         going invite nice meal chat  \n",
       "80   difficult listen says say something appropriat...  \n",
       "82                                                  hi  \n",
       "85                                                  hi  \n",
       "87   anyway brought home indian food know moving st...  \n",
       "90                                                      \n",
       "92                                               great  \n",
       "96                                           make home  \n",
       "98                                             welcome  \n",
       "106                            board like boards board  \n",
       "109                                                     \n",
       "111  least invent twenty six dimensions make math come  \n",
       "113                                           universe  \n",
       "121                                                 go  \n",
       "125                                 sit somewhere else  \n",
       "127                                        sheldon sit  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom stop words\n",
    "custom_stop_words = set(stopwords.words('english') + ['um'] + ['well'] + ['okay'] + ['uh'] + ['oh'] + ['yes'])\n",
    "\n",
    "# Remove stopwords\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in custom_stop_words]\n",
    "\n",
    "leonard_df['tokens_no_stop'] = leonard_df['tokens'].apply(remove_stopwords)\n",
    "leonard_df['dialogue_no_stop'] = leonard_df['tokens_no_stop'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "leonard_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0de4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging & NER\n",
    "def extract_entities(tokens):\n",
    "    entities = {'nouns': [], 'persons': []}\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'NOUN' and token.ent_type_ != 'PERSON':\n",
    "            entities['nouns'].append(token.lemma_)\n",
    "        elif token.ent_type_ == 'PERSON':\n",
    "            entities['persons'].append(token.text)\n",
    "    return entities\n",
    "\n",
    "leonard_df['entities'] = leonard_df['tokens_no_stop'].apply(extract_entities)\n",
    "\n",
    "# Flatten the lists of nouns and persons\n",
    "all_nouns = [noun for sublist in leonard_df['entities'].apply(lambda x: x['nouns']) for noun in sublist]\n",
    "all_persons = [person for sublist in leonard_df['entities'].apply(lambda x: x['persons']) for person in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c056f4eb",
   "metadata": {},
   "source": [
    "The words that were classified as nouns and person names are not entirely correct. We manually remove a few that stand out as wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c02c5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We manually remove some wrongly classified words\n",
    "not_nouns = [\"sheldon\", \"penny\", \"psst\", \"co\", \"lot\", \"talk\", \"call\", \"know\"]\n",
    "all_nouns = [noun for noun in all_nouns if noun not in not_nouns]\n",
    "not_persons = [\"ho\", \"yo\", \"mm\", \"come\", \"want\", \"little\", \"need\", \"relax\", \"reason\", \"long\", \"make\", \"hey\", \"tell\", \"talking\", \"knoks\", \"hang\", \"sorry\", \n",
    "               \"listen\", \"hmm\", \"cousin\", \"sister\", \"cool\", \"bisexual\", \"hell\", \"kinda\", \"rider\", \"head\", \"bag\", \"mmm\", \"hee\", \"talk\", \"cinnamon\", \"night\",\n",
    "              \"right\", \"bad\", \"fine\", \"lesbian\", \"know\", \"moo\", \"boy\", \"huh\", \"time\", \"nye\", \"na\", \"buh\", \"terrific\", \"heard\"]\n",
    "all_persons = [noun for noun in all_persons if noun not in not_persons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cddd45d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Noun Mentions: 12580\n",
      "Total Person Mentions: 972\n",
      "Total Unique Noun Mentions: 3101\n",
      "Total Unique Person Mentions: 446\n"
     ]
    }
   ],
   "source": [
    "# Create a frequency distribution of nouns and persons\n",
    "noun_freq = FreqDist(all_nouns)\n",
    "person_freq = FreqDist(all_persons)\n",
    "\n",
    "# Total counts\n",
    "total_noun_mentions = sum(noun_freq.values())\n",
    "total_person_mentions = sum(person_freq.values())\n",
    "\n",
    "print(f'Total Noun Mentions: {total_noun_mentions}')\n",
    "print(f'Total Person Mentions: {total_person_mentions}')\n",
    "print(f'Total Unique Noun Mentions: {len(set(all_nouns))}')\n",
    "print(f'Total Unique Person Mentions: {len(set(all_persons))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3c35c",
   "metadata": {},
   "source": [
    "We have to consider that there are still errors in how the words were tagged, but from the obtained results Leonard mentioned 3101 unique nouns for a total of 12580 times and 446 unique person names for a total of 972 times.\n",
    "\n",
    "We now generate word clouds to visualize the most frequently used nouns and person names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faa63674",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6092/358304001.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Generate Wordclouds using the wordcloud library\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnoun_wordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoun_freq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mperson_wordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperson_freq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Plot the Wordclouds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mfont_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m                 self.generate_from_frequencies(dict(frequencies[:2]),\n\u001b[0m\u001b[0;32m    454\u001b[0m                                                max_font_size=self.height)\n\u001b[0;32m    455\u001b[0m                 \u001b[1;31m# find font sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    506\u001b[0m                     font, orientation=orientation)\n\u001b[0;32m    507\u001b[0m                 \u001b[1;31m# get size of resulting text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m                 \u001b[0mbox_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransposed_font\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"lt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m                 \u001b[1;31m# find possible places using integral image:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                 result = occupancy.sample_position(box_size[3] + self.margin,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageDraw.py\u001b[0m in \u001b[0;36mtextbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreeTypeFont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Only supported for TrueType fonts\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"RGBA\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0membedded_color\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         bbox = font.getbbox(\n",
      "\u001b[1;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "# Generate Wordclouds using the wordcloud library\n",
    "noun_wordcloud = WordCloud(width=800, height=400, background_color='white', random_state=12).generate_from_frequencies(noun_freq)\n",
    "person_wordcloud = WordCloud(width=800, height=400, background_color='white', random_state=12).generate_from_frequencies(person_freq)\n",
    "\n",
    "# Plot the Wordclouds\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(noun_wordcloud, interpolation='bilinear')\n",
    "plt.title('Noun Wordcloud')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(person_wordcloud, interpolation='bilinear')\n",
    "plt.title('Person Name Wordcloud')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee3201",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "What are the most important words mentioned by your character? Do this analysis per episode, per season and overall over the first 10 seasons. To achieve this task, please first make a bag-of-words and/or use the TF-IDF statistical principle. Remark: You can try to make a Wordcloud for visualization, based on the given bag-of-words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958543a7",
   "metadata": {},
   "source": [
    "## Question 4\n",
    " Examine the co-occurence of words for your character by using the Positive Pointwise Mutual Information measurement. Which words are commonly used together in\n",
    "his/her dialogues? Remark: You can try to make a Word-Word co-occurence matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f89f42",
   "metadata": {},
   "source": [
    "The **word-word co-occurrence matrix** is created based on the tokens without stop words to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d0b7f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            agreed  point  excuse  one  across  aegean  eight  nabakov  \\\n",
      "point          1.0    0.0     0.0  1.0     0.0     0.0    0.0      0.0   \n",
      "flash          1.0    0.0     0.0  0.0     0.0     0.0    0.0      0.0   \n",
      "change         1.0    0.0     0.0  0.0     0.0     0.0    0.0      0.0   \n",
      "women          1.0    0.0     0.0  1.0     0.0     0.0    0.0      0.0   \n",
      "technology     1.0    0.0     0.0  0.0     0.0     0.0    0.0      0.0   \n",
      "...            ...    ...     ...  ...     ...     ...    ...      ...   \n",
      "assless        0.0    0.0     0.0  0.0     0.0     0.0    0.0      0.0   \n",
      "delicates      0.0    0.0     0.0  0.0     0.0     0.0    0.0      0.0   \n",
      "separating     0.0    0.0     0.0  0.0     0.0     0.0    0.0      0.0   \n",
      "paul           0.0    0.0     0.0  0.0     0.0     0.0    0.0      0.0   \n",
      "bunyan         0.0    0.0     0.0  0.0     0.0     0.0    0.0      0.0   \n",
      "\n",
      "            twenty  six  ...  arcadia  ibuprofen  ladders  depot  overly  \\\n",
      "point          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "flash          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "change         0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "women          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "technology     0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "...            ...  ...  ...      ...        ...      ...    ...     ...   \n",
      "assless        0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "delicates      0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "separating     0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "paul           0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "bunyan         0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "\n",
      "            fixated  premium  lactaid  pepto  legs  \n",
      "point           0.0      0.0      0.0    0.0   0.0  \n",
      "flash           0.0      0.0      0.0    0.0   0.0  \n",
      "change          0.0      0.0      0.0    0.0   0.0  \n",
      "women           0.0      0.0      0.0    0.0   0.0  \n",
      "technology      0.0      0.0      0.0    0.0   0.0  \n",
      "...             ...      ...      ...    ...   ...  \n",
      "assless         0.0      0.0      0.0    0.0   0.0  \n",
      "delicates       0.0      0.0      0.0    0.0   0.0  \n",
      "separating      0.0      0.0      0.0    0.0   0.0  \n",
      "paul            0.0      0.0      0.0    0.0   0.0  \n",
      "bunyan          0.0      0.0      0.0    0.0   0.0  \n",
      "\n",
      "[6834 rows x 6936 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creating the word-word co-occurence matrix\n",
    "tokens_column = leonard_df['tokens_no_stop']\n",
    "\n",
    "# Empty co-occurrence matrix\n",
    "co_occurrence_matrix = {}\n",
    "\n",
    "window_size = 2\n",
    "\n",
    "# Iterate through each list of tokens in the column\n",
    "for tokens in tokens_column:\n",
    "    # Iterate through each word in the list of tokens\n",
    "    for i, word in enumerate(tokens):\n",
    "        # Define the context window\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(tokens), i + window_size + 1)\n",
    "\n",
    "        # Extract the context words\n",
    "        context = tokens[start:i] + tokens[i+1:end]\n",
    "\n",
    "        # Update the co-occurrence matrix\n",
    "        if word not in co_occurrence_matrix:\n",
    "            co_occurrence_matrix[word] = {}\n",
    "\n",
    "        for neighbor in context:\n",
    "            if neighbor not in co_occurrence_matrix[word]:\n",
    "                co_occurrence_matrix[word][neighbor] = 0\n",
    "            co_occurrence_matrix[word][neighbor] += 1\n",
    "\n",
    "# Convert co-occurrence matrix to a df\n",
    "co_occurrence_df = pd.DataFrame(co_occurrence_matrix).fillna(0)\n",
    "print(co_occurrence_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f57cba",
   "metadata": {},
   "source": [
    "Next, the **Pointwise Mutual Information** measurement is calculated to examine the co-occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd893075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMI \n",
    "\n",
    "def calculate_pmi(co_occurrence_df):\n",
    "    co_occurrence_matrix = co_occurrence_df.to_numpy()\n",
    "    words = co_occurrence_df.index.tolist()\n",
    "\n",
    "    total_sum = np.sum(co_occurrence_matrix)\n",
    "    row_sum = np.sum(co_occurrence_matrix, axis=1)\n",
    "    col_sum = np.sum(co_occurrence_matrix, axis=0)\n",
    "\n",
    "    for i in range(co_occurrence_matrix.shape[0]):\n",
    "        for j in range(co_occurrence_matrix.shape[1]):\n",
    "            co_occurrence_count = co_occurrence_matrix[i, j]\n",
    "\n",
    "            if co_occurrence_count == 0:\n",
    "                continue\n",
    "\n",
    "            p_x_y = co_occurrence_count / total_sum\n",
    "            p_x = row_sum[i] / total_sum\n",
    "            p_y = col_sum[j] / total_sum\n",
    "\n",
    "            pmi = np.log(p_x_y / (p_x * p_y)) # PMI formula \n",
    "\n",
    "            co_occurrence_df.iloc[i, j] = pmi\n",
    "\n",
    "    return co_occurrence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f84d4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMI Matrix:\n",
      "              agreed  point  excuse       one  across  aegean  eight  nabakov  \\\n",
      "point       3.896185    0.0     0.0  0.279144     0.0     0.0    0.0      0.0   \n",
      "flash       5.368657    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "change      4.180814    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "women       3.704731    0.0     0.0  0.087689     0.0     0.0    0.0      0.0   \n",
      "technology  5.643094    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "...              ...    ...     ...       ...     ...     ...    ...      ...   \n",
      "assless     0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "delicates   0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "separating  0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "paul        0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "bunyan      0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "\n",
      "            twenty  six  ...  arcadia  ibuprofen  ladders  depot  overly  \\\n",
      "point          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "flash          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "change         0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "women          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "technology     0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "...            ...  ...  ...      ...        ...      ...    ...     ...   \n",
      "assless        0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "delicates      0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "separating     0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "paul           0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "bunyan         0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "\n",
      "            fixated  premium  lactaid  pepto  legs  \n",
      "point           0.0      0.0      0.0    0.0   0.0  \n",
      "flash           0.0      0.0      0.0    0.0   0.0  \n",
      "change          0.0      0.0      0.0    0.0   0.0  \n",
      "women           0.0      0.0      0.0    0.0   0.0  \n",
      "technology      0.0      0.0      0.0    0.0   0.0  \n",
      "...             ...      ...      ...    ...   ...  \n",
      "assless         0.0      0.0      0.0    0.0   0.0  \n",
      "delicates       0.0      0.0      0.0    0.0   0.0  \n",
      "separating      0.0      0.0      0.0    0.0   0.0  \n",
      "paul            0.0      0.0      0.0    0.0   0.0  \n",
      "bunyan          0.0      0.0      0.0    0.0   0.0  \n",
      "\n",
      "[6834 rows x 6936 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print PMI matrix\n",
    "co_occurrence_df_pmi = calculate_pmi(co_occurrence_df.copy())\n",
    "\n",
    "print(\"PMI Matrix:\")\n",
    "print(co_occurrence_df_pmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c595083",
   "metadata": {},
   "source": [
    "We take a look at the **10 highest and lowest PMI values** to check out the bounds and which words co-occur the most and least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "798dc3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 highest PMI values:\n",
      "                 level_0                level_1          0\n",
      "0           substitution              reduction  11.678575\n",
      "1              reduction           substitution  11.678575\n",
      "2                    eta                  meson  11.678575\n",
      "3                  meson                    eta  11.678575\n",
      "4  anythingforagreencard                    com  11.678575\n",
      "5                    com  anythingforagreencard  11.678575\n",
      "6              reiterate                knuckle  11.678575\n",
      "7                knuckle              reiterate  11.678575\n",
      "8             saturnalia                miracle  11.678575\n",
      "9                miracle             saturnalia  11.678575\n",
      "\n",
      "Bottom 10 lowest PMI values:\n",
      "  level_0 level_1         0\n",
      "0    like      na -2.160503\n",
      "1      na    like -2.160503\n",
      "2     see    know -2.118221\n",
      "3    know     see -2.118221\n",
      "4    like     gon -2.057710\n",
      "5     gon    like -2.057710\n",
      "6    like     let -2.054857\n",
      "7     let    like -2.054857\n",
      "8     get    good -1.986015\n",
      "9    good     get -1.986015\n"
     ]
    }
   ],
   "source": [
    "# Filter to show the 10 highest PMI values\n",
    "top_10_pmi = co_occurrence_df_pmi.unstack().nlargest(10).reset_index()\n",
    "print(\"Top 10 highest PMI values:\")\n",
    "print(top_10_pmi)\n",
    "\n",
    "# Filter to show the 10 lowest PMI values\n",
    "bottom_10_pmi = co_occurrence_df_pmi.unstack().nsmallest(10).reset_index()\n",
    "print(\"\\nBottom 10 lowest PMI values:\")\n",
    "print(bottom_10_pmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0b421",
   "metadata": {},
   "source": [
    "We can see that the bounds are around [-2.2;11.7], but these bounds are not fixed, because they depend on the probabilities we have. A big disadvantage is that these PMI values can take negative and positive values, and are very difficult to interpret due to these unfixed bounds, as well as due to its biasness towards infrequent words. \n",
    "\n",
    "Since the negative PMI values tend to be unreliable, we try a variation which is called the **Positive Pointwise Mutual Information** measurement. This variation deals with the negative PMI values by setting them to zero, since they are hardly interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39129bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive PMI\n",
    "\n",
    "def calculate_ppmi(co_occurrence_df):\n",
    "    co_occurrence_matrix = co_occurrence_df.to_numpy()\n",
    "    words = co_occurrence_df.index.tolist()\n",
    "\n",
    "    total_sum = np.sum(co_occurrence_matrix)\n",
    "    row_sum = np.sum(co_occurrence_matrix, axis=1)\n",
    "    col_sum = np.sum(co_occurrence_matrix, axis=0)\n",
    "\n",
    "    for i in range(co_occurrence_matrix.shape[0]):\n",
    "        for j in range(co_occurrence_matrix.shape[1]):\n",
    "            co_occurrence_count = co_occurrence_matrix[i, j]\n",
    "\n",
    "            if co_occurrence_count == 0:\n",
    "                continue\n",
    "\n",
    "            p_x_y = co_occurrence_count / total_sum\n",
    "            p_x = row_sum[i] / total_sum\n",
    "            p_y = col_sum[j] / total_sum\n",
    "\n",
    "            pmi = np.log(p_x_y / (p_x * p_y)) # PPMI formula (negative values become zero)\n",
    "            ppmi = max(pmi, 0) \n",
    "\n",
    "            co_occurrence_df.iloc[i, j] = ppmi\n",
    "\n",
    "    return co_occurrence_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ebc1cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPMI Matrix:\n",
      "              agreed  point  excuse       one  across  aegean  eight  nabakov  \\\n",
      "point       3.896185    0.0     0.0  0.279144     0.0     0.0    0.0      0.0   \n",
      "flash       5.368657    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "change      4.180814    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "women       3.704731    0.0     0.0  0.087689     0.0     0.0    0.0      0.0   \n",
      "technology  5.643094    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "...              ...    ...     ...       ...     ...     ...    ...      ...   \n",
      "assless     0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "delicates   0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "separating  0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "paul        0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "bunyan      0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "\n",
      "            twenty  six  ...  arcadia  ibuprofen  ladders  depot  overly  \\\n",
      "point          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "flash          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "change         0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "women          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "technology     0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "...            ...  ...  ...      ...        ...      ...    ...     ...   \n",
      "assless        0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "delicates      0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "separating     0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "paul           0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "bunyan         0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "\n",
      "            fixated  premium  lactaid  pepto  legs  \n",
      "point           0.0      0.0      0.0    0.0   0.0  \n",
      "flash           0.0      0.0      0.0    0.0   0.0  \n",
      "change          0.0      0.0      0.0    0.0   0.0  \n",
      "women           0.0      0.0      0.0    0.0   0.0  \n",
      "technology      0.0      0.0      0.0    0.0   0.0  \n",
      "...             ...      ...      ...    ...   ...  \n",
      "assless         0.0      0.0      0.0    0.0   0.0  \n",
      "delicates       0.0      0.0      0.0    0.0   0.0  \n",
      "separating      0.0      0.0      0.0    0.0   0.0  \n",
      "paul            0.0      0.0      0.0    0.0   0.0  \n",
      "bunyan          0.0      0.0      0.0    0.0   0.0  \n",
      "\n",
      "[6834 rows x 6936 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print PPMI matrix\n",
    "co_occurrence_df_ppmi = calculate_ppmi(co_occurrence_df.copy())\n",
    "\n",
    "print(\"PPMI Matrix:\")\n",
    "print(co_occurrence_df_ppmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2bc5711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 highest PPMI values:\n",
      "                 level_0                level_1          0\n",
      "0           substitution              reduction  11.678575\n",
      "1              reduction           substitution  11.678575\n",
      "2                    eta                  meson  11.678575\n",
      "3                  meson                    eta  11.678575\n",
      "4  anythingforagreencard                    com  11.678575\n",
      "5                    com  anythingforagreencard  11.678575\n",
      "6              reiterate                knuckle  11.678575\n",
      "7                knuckle              reiterate  11.678575\n",
      "8             saturnalia                miracle  11.678575\n",
      "9                miracle             saturnalia  11.678575\n",
      "\n",
      "Bottom 10 lowest PPMI values:\n",
      "  level_0   level_1    0\n",
      "0  agreed    agreed  0.0\n",
      "1  agreed    pupils  0.0\n",
      "2  agreed     guess  0.0\n",
      "3  agreed  bringing  0.0\n",
      "4  agreed     think  0.0\n",
      "5  agreed      made  0.0\n",
      "6  agreed      play  0.0\n",
      "7  agreed     teams  0.0\n",
      "8  agreed       cut  0.0\n",
      "9  agreed       raj  0.0\n"
     ]
    }
   ],
   "source": [
    "# Filter to show the 10 highest PPMI values\n",
    "top_10_ppmi = co_occurrence_df_ppmi.unstack().nlargest(10).reset_index()\n",
    "print(\"Top 10 highest PPMI values:\")\n",
    "print(top_10_ppmi)\n",
    "\n",
    "# Filter to show the 10 lowest PPMI values\n",
    "bottom_10_ppmi = co_occurrence_df_ppmi.unstack().nsmallest(10).reset_index()\n",
    "print(\"\\nBottom 10 lowest PPMI values:\")\n",
    "print(bottom_10_ppmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b269fb",
   "metadata": {},
   "source": [
    "We see that the bounds for the PPMI values are [0;11.7], and the negative PMI values are now avoided since they were changed to zero. \n",
    "\n",
    "However, interpretation is still difficult, which is why we try another adaptation called the **Normalized Pointwise Mutual Information** measurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b39e4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized PMI\n",
    "\n",
    "def calculate_npmi(co_occurrence_df):\n",
    "    co_occurrence_matrix = co_occurrence_df.to_numpy()\n",
    "    words = co_occurrence_df.index.tolist()\n",
    "\n",
    "    total_sum = np.sum(co_occurrence_matrix)\n",
    "    row_sum = np.sum(co_occurrence_matrix, axis=1)\n",
    "    col_sum = np.sum(co_occurrence_matrix, axis=0)\n",
    "\n",
    "    for i in range(co_occurrence_matrix.shape[0]):\n",
    "        for j in range(co_occurrence_matrix.shape[1]):\n",
    "            co_occurrence_count = co_occurrence_matrix[i, j]\n",
    "\n",
    "            if co_occurrence_count == 0:\n",
    "                continue\n",
    "\n",
    "            p_x_y = co_occurrence_count / total_sum\n",
    "            p_x = row_sum[i] / total_sum\n",
    "            p_y = col_sum[j] / total_sum\n",
    "\n",
    "            pmi = np.log(p_x_y / (p_x * p_y)) \n",
    "            npmi = pmi / (-np.log(p_x_y))      # NPMI formula\n",
    "\n",
    "            co_occurrence_df.iloc[i, j] = npmi\n",
    "\n",
    "    return co_occurrence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4a69afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPMI Matrix:\n",
      "              agreed  point  excuse       one  across  aegean  eight  nabakov  \\\n",
      "point       0.333618    0.0     0.0  0.023902     0.0     0.0    0.0      0.0   \n",
      "flash       0.459701    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "change      0.357990    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "women       0.317225    0.0     0.0  0.007509     0.0     0.0    0.0      0.0   \n",
      "technology  0.483201    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "...              ...    ...     ...       ...     ...     ...    ...      ...   \n",
      "assless     0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "delicates   0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "separating  0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "paul        0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "bunyan      0.000000    0.0     0.0  0.000000     0.0     0.0    0.0      0.0   \n",
      "\n",
      "            twenty  six  ...  arcadia  ibuprofen  ladders  depot  overly  \\\n",
      "point          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "flash          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "change         0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "women          0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "technology     0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "...            ...  ...  ...      ...        ...      ...    ...     ...   \n",
      "assless        0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "delicates      0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "separating     0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "paul           0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "bunyan         0.0  0.0  ...      0.0        0.0      0.0    0.0     0.0   \n",
      "\n",
      "            fixated  premium  lactaid  pepto  legs  \n",
      "point           0.0      0.0      0.0    0.0   0.0  \n",
      "flash           0.0      0.0      0.0    0.0   0.0  \n",
      "change          0.0      0.0      0.0    0.0   0.0  \n",
      "women           0.0      0.0      0.0    0.0   0.0  \n",
      "technology      0.0      0.0      0.0    0.0   0.0  \n",
      "...             ...      ...      ...    ...   ...  \n",
      "assless         0.0      0.0      0.0    0.0   0.0  \n",
      "delicates       0.0      0.0      0.0    0.0   0.0  \n",
      "separating      0.0      0.0      0.0    0.0   0.0  \n",
      "paul            0.0      0.0      0.0    0.0   0.0  \n",
      "bunyan          0.0      0.0      0.0    0.0   0.0  \n",
      "\n",
      "[6834 rows x 6936 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print NPMI matrix\n",
    "co_occurrence_df = calculate_npmi(co_occurrence_df)\n",
    "\n",
    "print(\"NPMI Matrix:\")\n",
    "print(co_occurrence_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74bd8732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows and columns with highest NPMI values:\n",
      "                 level_0                level_1    0\n",
      "0           substitution              reduction  1.0\n",
      "1              reduction           substitution  1.0\n",
      "2                    eta                  meson  1.0\n",
      "3                  meson                    eta  1.0\n",
      "4  anythingforagreencard                    com  1.0\n",
      "5                    com  anythingforagreencard  1.0\n",
      "6              reiterate                knuckle  1.0\n",
      "7                knuckle              reiterate  1.0\n",
      "8                   psst                   psst  1.0\n",
      "9                     oo                     oo  1.0\n",
      "\n",
      "Bottom 5 rows and columns with lowest NPMI values:\n",
      "  level_0 level_1         0\n",
      "0    like      na -0.184997\n",
      "1      na    like -0.184997\n",
      "2     see    know -0.181377\n",
      "3    know     see -0.181377\n",
      "4    like     gon -0.176195\n",
      "5     gon    like -0.176195\n",
      "6    like     let -0.175951\n",
      "7     let    like -0.175951\n",
      "8     get    good -0.170056\n",
      "9    good     get -0.170056\n"
     ]
    }
   ],
   "source": [
    "# Filter to show the 10 highest NPMI values\n",
    "top_10_npmi = co_occurrence_df.unstack().nlargest(10).reset_index()\n",
    "print(\"Top 10 highest NPMI values:\")\n",
    "print(top_10_npmi)\n",
    "\n",
    "# Filter to show the 10 lowest NPMI values\n",
    "bottom_10_npmi = co_occurrence_df.unstack().nsmallest(10).reset_index()\n",
    "print(\"\\nBottom 10 lowest NPMI values:\")\n",
    "print(bottom_10_npmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1706c46f",
   "metadata": {},
   "source": [
    "The Normalized PMI values are bound between -1 and 1, which allows for a better interpretation of the co-occurrence of the words in our corpus. Values of -1 indicate that the words never occur together, values of 0 indicate independence between the words, and values of 1 indicate complete co-occurrence of the words. \n",
    "\n",
    "Based on the 10 highest and lowest NPMI values, we can see that very specific words, e.g. 'substitution' and 'reduction' always occur together. Let's a closer look at the words with a NPMI value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b4c9077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 60 highest NPMI values:\n",
      "                  level_0                level_1         0\n",
      "0            substitution              reduction  1.000000\n",
      "1               reduction           substitution  1.000000\n",
      "2                     eta                  meson  1.000000\n",
      "3                   meson                    eta  1.000000\n",
      "4   anythingforagreencard                    com  1.000000\n",
      "5                     com  anythingforagreencard  1.000000\n",
      "6               reiterate                knuckle  1.000000\n",
      "7                 knuckle              reiterate  1.000000\n",
      "8                    psst                   psst  1.000000\n",
      "9                      oo                     oo  1.000000\n",
      "10             saturnalia                miracle  1.000000\n",
      "11                miracle             saturnalia  1.000000\n",
      "12            extenuating          circumstances  1.000000\n",
      "13          circumstances            extenuating  1.000000\n",
      "14                 rupert                murdoch  1.000000\n",
      "15                murdoch                 rupert  1.000000\n",
      "16               darkness                   bind  1.000000\n",
      "17                   bind               darkness  1.000000\n",
      "18                  seedy             underbelly  1.000000\n",
      "19             underbelly                  seedy  1.000000\n",
      "20              acetylene                  torch  1.000000\n",
      "21                  torch              acetylene  1.000000\n",
      "22               sulfites              migraines  1.000000\n",
      "23              migraines               sulfites  1.000000\n",
      "24                     ay                   papi  1.000000\n",
      "25                   papi                     ay  1.000000\n",
      "26           interrupting                  physi  1.000000\n",
      "27                  physi           interrupting  1.000000\n",
      "28             gelatinous                 sphere  1.000000\n",
      "29                 sphere             gelatinous  1.000000\n",
      "30               lobsters              overnight  1.000000\n",
      "31              overnight               lobsters  1.000000\n",
      "32                    tar                   pits  1.000000\n",
      "33                   pits                    tar  1.000000\n",
      "34                indoors              sunscreen  1.000000\n",
      "35              sunscreen                indoors  1.000000\n",
      "36             attendance                implies  1.000000\n",
      "37                implies             attendance  1.000000\n",
      "38                assless                  chaps  1.000000\n",
      "39                  chaps                assless  1.000000\n",
      "40             separating              delicates  1.000000\n",
      "41              delicates             separating  1.000000\n",
      "42                   mwuh                   mwuh  0.957043\n",
      "43                    shh                    shh  0.949889\n",
      "44                    duh                    duh  0.944216\n",
      "45                     ba                     ba  0.944035\n",
      "46                doctors                  flirt  0.940648\n",
      "47                cameras               infrared  0.940648\n",
      "48               suffered                silence  0.940648\n",
      "49                silence               suffered  0.940648\n",
      "50               infrared                cameras  0.940648\n",
      "51                  flirt                doctors  0.940648\n",
      "52                    moo                 stache  0.936903\n",
      "53                 stache                    moo  0.936903\n",
      "54                     un            unravelable  0.905929\n",
      "55            unravelable                     un  0.905929\n",
      "56                   ahoy                  matey  0.905929\n",
      "57                  matey                   ahoy  0.905929\n",
      "58               stitches                 needle  0.905929\n",
      "59                 needle               stitches  0.905929\n"
     ]
    }
   ],
   "source": [
    "# Filter to show the 60 highest NPMI values\n",
    "top_60_npmi = co_occurrence_df.unstack().nlargest(60).reset_index()\n",
    "print(\"Top 60 highest NPMI values:\")\n",
    "print(top_60_npmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182d4c1",
   "metadata": {},
   "source": [
    "Very specific words have NPMI values of 1, which indicate complete co-occurrence and means that they are always mentioned together, since they're not likely to occur in another sentence or context paired with a different word. However, a word such as 'doctors' could be used in different contexts and sentences, but we see that Leonard pairs 'doctors' often with 'flirt' , since it has a NPMI value of 0.940. This shows the limitation of the Normalized PMI: although it is interpretable, it still has a biasness towards infrequent words. We imagine that Leonard does not use the specific words with an NPMI value of 1 very often in his dialogues. \n",
    "\n",
    "To circumvent this limitation, we finally try the **PMI to the k-th family** measurement. This adaptation of the PMI addresses both the interpretability issue and the biasness towards infrequent events issue of the PMI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811aaad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
