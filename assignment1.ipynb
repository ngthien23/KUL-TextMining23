{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "import pandas as pd\n",
    "path = 'Scripts TBBT.csv'\n",
    "df = pd.read_csv(path,sep=',',skipinitialspace=True,engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove every punctuation from the dataframe\n",
    "import string\n",
    "\n",
    "# Function to remove punctuations\n",
    "def remove_punctuations(text):\n",
    "\n",
    "    # Check if the value is a string, then remove punctuations\n",
    "    if isinstance(text, str):\n",
    "        return text.translate(str.maketrans('', '', string.punctuation))\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Removing punctuations from string columns\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for person_scene that contains Leonard\n",
    "df = df[df['person_scene'].str.contains('Leonard')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase the whole dataframe\n",
    "df = df.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\camd1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords with NLTK for column dialogue\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "df['dialogue'] = df['dialogue'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Porter stemmer to perform stemming on the used words in dialogue\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "df['dialogue'] = df['dialogue'].apply(lambda x: ' '.join([porter.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform POS tagging & NER tagging on the dialogue column with Spacy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Function to perform POS tagging and NER tagging\n",
    "def pos_ner_tagging(text):\n",
    "    doc = nlp(text)\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "    ner_tags = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "    return pos_tags, ner_tags\n",
    "\n",
    "# Apply POS and NER tagging to the 'dialogue' column\n",
    "df[['POS_tags', 'NER_tags']] = df['dialogue'].apply(lambda x: pd.Series(pos_ner_tagging(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_name</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>person_scene</th>\n",
       "      <th>POS_tags</th>\n",
       "      <th>NER_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50720</th>\n",
       "      <td>series 10 episode 09 – the geology elevation</td>\n",
       "      <td>well chang plaqu mixedrac coupl grandma</td>\n",
       "      <td>leonard</td>\n",
       "      <td>[(well, INTJ), (chang, PROPN), (plaqu, PROPN),...</td>\n",
       "      <td>[(chang, PERSON), (mixedrac coupl, PERSON)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23993</th>\n",
       "      <td>series 05 episode 14 – the beta test initiation</td>\n",
       "      <td>thank</td>\n",
       "      <td>leonard</td>\n",
       "      <td>[(thank, VERB)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>series 01 episode 15 – the porkchop indeterminacy</td>\n",
       "      <td>two know</td>\n",
       "      <td>leonard</td>\n",
       "      <td>[(two, NUM), (know, VERB)]</td>\n",
       "      <td>[(two, CARDINAL)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33018</th>\n",
       "      <td>series 07 episode 08 – the itchy brain simulation</td>\n",
       "      <td>look there’ there’ there’ ticket</td>\n",
       "      <td>leonard</td>\n",
       "      <td>[(look, VERB), (there, ADV), (’, PUNCT), (ther...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12347</th>\n",
       "      <td>series 03 episode 11 – the maternal congruence</td>\n",
       "      <td>it’</td>\n",
       "      <td>leonard</td>\n",
       "      <td>[(it, PRON), (’, PUNCT)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44050</th>\n",
       "      <td>series 09 episode 06 – the helium insufficiency</td>\n",
       "      <td>let’ start experi</td>\n",
       "      <td>leonard</td>\n",
       "      <td>[(let, VERB), (’, PUNCT), (start, VERB), (expe...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43955</th>\n",
       "      <td>series 09 episode 06 – the helium insufficiency</td>\n",
       "      <td>sure</td>\n",
       "      <td>leonard</td>\n",
       "      <td>[(sure, ADV)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3384</th>\n",
       "      <td>series 01 episode 14 – the nerdvana annihilation</td>\n",
       "      <td>come sniper</td>\n",
       "      <td>leonard</td>\n",
       "      <td>[(come, VERB), (sniper, NOUN)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51985</th>\n",
       "      <td>series 10 episode 15 – the locomotion reverber...</td>\n",
       "      <td>good cut edg new technolog still make inapprop...</td>\n",
       "      <td>leonard</td>\n",
       "      <td>[(good, ADJ), (cut, VERB), (edg, NOUN), (new, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31883</th>\n",
       "      <td>series 07 episode 03 – the scavenger vortex</td>\n",
       "      <td>great</td>\n",
       "      <td>leonard</td>\n",
       "      <td>[(great, ADJ)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            episode_name  \\\n",
       "50720       series 10 episode 09 – the geology elevation   \n",
       "23993    series 05 episode 14 – the beta test initiation   \n",
       "3631   series 01 episode 15 – the porkchop indeterminacy   \n",
       "33018  series 07 episode 08 – the itchy brain simulation   \n",
       "12347     series 03 episode 11 – the maternal congruence   \n",
       "44050    series 09 episode 06 – the helium insufficiency   \n",
       "43955    series 09 episode 06 – the helium insufficiency   \n",
       "3384    series 01 episode 14 – the nerdvana annihilation   \n",
       "51985  series 10 episode 15 – the locomotion reverber...   \n",
       "31883        series 07 episode 03 – the scavenger vortex   \n",
       "\n",
       "                                                dialogue person_scene  \\\n",
       "50720            well chang plaqu mixedrac coupl grandma      leonard   \n",
       "23993                                              thank      leonard   \n",
       "3631                                            two know      leonard   \n",
       "33018                   look there’ there’ there’ ticket      leonard   \n",
       "12347                                                it’      leonard   \n",
       "44050                                  let’ start experi      leonard   \n",
       "43955                                               sure      leonard   \n",
       "3384                                         come sniper      leonard   \n",
       "51985  good cut edg new technolog still make inapprop...      leonard   \n",
       "31883                                              great      leonard   \n",
       "\n",
       "                                                POS_tags  \\\n",
       "50720  [(well, INTJ), (chang, PROPN), (plaqu, PROPN),...   \n",
       "23993                                    [(thank, VERB)]   \n",
       "3631                          [(two, NUM), (know, VERB)]   \n",
       "33018  [(look, VERB), (there, ADV), (’, PUNCT), (ther...   \n",
       "12347                           [(it, PRON), (’, PUNCT)]   \n",
       "44050  [(let, VERB), (’, PUNCT), (start, VERB), (expe...   \n",
       "43955                                      [(sure, ADV)]   \n",
       "3384                      [(come, VERB), (sniper, NOUN)]   \n",
       "51985  [(good, ADJ), (cut, VERB), (edg, NOUN), (new, ...   \n",
       "31883                                     [(great, ADJ)]   \n",
       "\n",
       "                                          NER_tags  \n",
       "50720  [(chang, PERSON), (mixedrac coupl, PERSON)]  \n",
       "23993                                           []  \n",
       "3631                             [(two, CARDINAL)]  \n",
       "33018                                           []  \n",
       "12347                                           []  \n",
       "44050                                           []  \n",
       "43955                                           []  \n",
       "3384                                            []  \n",
       "51985                                           []  \n",
       "31883                                           []  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print random 20 rows of the dataframe\n",
    "df.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
